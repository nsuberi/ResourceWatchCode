{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality Control Considerations\n",
    "\n",
    "* Datetime format == UTC compliant: True\n",
    "* Long form: True\n",
    "* Duplicate records: Under development\n",
    "* Locations and History tables in sync: JUST USE RECENT DATA ENDPOINT Under development\n",
    "\n",
    "# Priority\n",
    "* Insert into Carto\n",
    "* Design a widget to show updating data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carto: Authentication and URL setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Base URL for all SQL calls\n",
    "carto_url = \"https://wri-rw.carto.com/api/v2/sql\"\n",
    "\n",
    "# Authentication credentials:\n",
    "config = ConfigParser()\n",
    "config.read(\"/Users/nathansuberi/Desktop/Code Portfolio/ResourceWatchCode/.env\")\n",
    "# FROM: https://resourcewatch.carto.com/u/wri-rw/your_apps\n",
    "carto_api_token = config.get(\"auth\", \"carto_api_token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Access internet resources\n",
    "import requests as req\n",
    "# Parse json\n",
    "import json\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Using datetime objects to ensure UTC time in incoming data\n",
    "from datetime import datetime, timedelta\n",
    "# Retrieve credentials from a local .env file\n",
    "from configparser import ConfigParser\n",
    "\n",
    "# S3 connection libraries\n",
    "# Need to have environmental variables set with \"aws configure\", \n",
    "# or update code to explicitly supplied AWS Access Id and AWS Secret Key\n",
    "import boto3\n",
    "import sys\n",
    "import threading\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "s3_resource = boto3.resource(\"s3\")\n",
    "\n",
    "class ProgressPercentage(object):\n",
    "        def __init__(self, filename):\n",
    "            self._filename = filename\n",
    "            self._size = float(os.path.getsize(filename))\n",
    "            self._seen_so_far = 0\n",
    "            self._lock = threading.Lock()\n",
    "\n",
    "        def __call__(self, bytes_amount):\n",
    "            # To simplify we'll assume this is hooked up\n",
    "            # to a single filename.\n",
    "            with self._lock:\n",
    "                self._seen_so_far += bytes_amount\n",
    "                percentage = (self._seen_so_far / self._size) * 100\n",
    "                sys.stdout.write(\"\\r%s  %s / %s  (%.2f%%)\"%(\n",
    "                        self._filename, self._seen_so_far, self._size,\n",
    "                        percentage))\n",
    "                sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Pandas to read a CSV from a public s3 account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate records between two days: 0\n",
      "Dec 8 times: ['2017-12-08T00:00:00.000Z' '2017-12-08T01:00:00.000Z'\n",
      " '2017-12-08T02:00:00.000Z' ..., '2017-12-08T22:24:09.000Z'\n",
      " '2017-12-08T22:22:26.000Z' '2017-12-08T22:24:26.000Z']\n",
      "Dec 9 times: ['2017-12-09T00:00:00.000Z' '2017-12-09T01:00:00.000Z'\n",
      " '2017-12-09T02:00:00.000Z' ..., '2017-12-09T23:42:00.000Z'\n",
      " '2017-12-09T22:44:19.000Z' '2017-12-09T22:44:17.000Z']\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/32400867/pandas-read-csv-from-url/41880513#41880513\n",
    "# http://www.ritchieng.com/pandas-removing-duplicate-rows/\n",
    "url = \"https://openaq-data.s3.amazonaws.com/2017-12-09.csv\"\n",
    "dec9 = pd.read_csv(url)\n",
    "url = \"https://openaq-data.s3.amazonaws.com/2017-12-08.csv\"\n",
    "dec8 = pd.read_csv(url)\n",
    "twodays = dec9.append(dec8)\n",
    "dupes = twodays.duplicated()\n",
    "print(\"Number of duplicate records between two days:\", dupes.sum())\n",
    "print(\"Dec 8 times:\", dec8.utc.unique())\n",
    "print(\"Dec 9 times:\", dec9.utc.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add locations from these two sample days, make sure that further adds are successfully de-duped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "kwargs = {\n",
    "    \"data_df\":dec8,\n",
    "    \"target_table_name\":\"open_aq_locations\",\n",
    "    \"cols_and_types\":cols_and_types_locations,\n",
    "    \"cols_with_apostrophes\":[\"location\", \"city\",\"country\"]\n",
    "}\n",
    "\n",
    "update_table_without_duplicates(**kwargs)\n",
    "update_table_without_duplicates(**kwargs)\n",
    "\n",
    "kwargs = {\n",
    "    \"data_df\":dec9,\n",
    "    \"target_table_name\":\"open_aq_locations\",\n",
    "    \"cols_and_types\":cols_and_types_locations,\n",
    "    \"cols_with_apostrophes\":[\"location\", \"city\",\"country\"]\n",
    "}\n",
    "\n",
    "update_table_without_duplicates(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over all CSVs in the OpenAQ record and capture the unique locations.\n",
    "\n",
    "Locations are included as long as they have the same \"location\", \"city\", \"country\" fields, and their \"latitude\" and \"longitude\" fields are equal to 6 significant figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2015-06-29.csv',\n",
       " '2015-06-30.csv',\n",
       " '2015-07-01.csv',\n",
       " '2015-07-02.csv',\n",
       " '2015-07-03.csv',\n",
       " '2015-07-04.csv',\n",
       " '2015-07-06.csv',\n",
       " '2015-07-07.csv',\n",
       " '2015-07-08.csv',\n",
       " '2015-07-09.csv',\n",
       " '2015-07-10.csv',\n",
       " '2015-07-11.csv',\n",
       " '2015-07-12.csv',\n",
       " '2015-07-13.csv',\n",
       " '2015-07-14.csv',\n",
       " '2015-07-15.csv',\n",
       " '2015-07-16.csv',\n",
       " '2015-07-17.csv',\n",
       " '2015-07-18.csv',\n",
       " '2015-07-20.csv',\n",
       " '2015-07-21.csv',\n",
       " '2015-07-22.csv',\n",
       " '2015-07-23.csv',\n",
       " '2015-07-24.csv',\n",
       " '2015-08-02.csv',\n",
       " '2015-08-03.csv',\n",
       " '2015-08-04.csv',\n",
       " '2015-08-05.csv',\n",
       " '2015-08-06.csv',\n",
       " '2015-08-07.csv',\n",
       " '2015-08-08.csv',\n",
       " '2015-08-09.csv',\n",
       " '2015-08-10.csv',\n",
       " '2015-08-11.csv',\n",
       " '2015-08-12.csv',\n",
       " '2015-08-13.csv',\n",
       " '2015-08-14.csv',\n",
       " '2015-08-15.csv',\n",
       " '2015-08-16.csv',\n",
       " '2015-08-17.csv',\n",
       " '2015-08-18.csv',\n",
       " '2015-08-19.csv',\n",
       " '2015-08-20.csv',\n",
       " '2015-08-21.csv',\n",
       " '2015-08-22.csv',\n",
       " '2015-08-23.csv',\n",
       " '2015-08-24.csv',\n",
       " '2015-08-25.csv',\n",
       " '2015-08-26.csv',\n",
       " '2015-08-27.csv',\n",
       " '2015-08-28.csv',\n",
       " '2015-08-29.csv',\n",
       " '2015-08-30.csv',\n",
       " '2015-08-31.csv',\n",
       " '2015-09-01.csv',\n",
       " '2015-09-02.csv',\n",
       " '2015-09-03.csv',\n",
       " '2015-09-04.csv',\n",
       " '2015-09-05.csv',\n",
       " '2015-09-06.csv',\n",
       " '2015-09-07.csv',\n",
       " '2015-09-08.csv',\n",
       " '2015-09-09.csv',\n",
       " '2015-09-10.csv',\n",
       " '2015-09-11.csv',\n",
       " '2015-09-12.csv',\n",
       " '2015-09-13.csv',\n",
       " '2015-09-14.csv',\n",
       " '2015-09-15.csv',\n",
       " '2015-09-16.csv',\n",
       " '2015-09-17.csv',\n",
       " '2015-09-18.csv',\n",
       " '2015-09-19.csv',\n",
       " '2015-09-20.csv',\n",
       " '2015-09-21.csv',\n",
       " '2015-09-22.csv',\n",
       " '2015-09-23.csv',\n",
       " '2015-09-24.csv',\n",
       " '2015-09-25.csv',\n",
       " '2015-09-26.csv',\n",
       " '2015-09-27.csv',\n",
       " '2015-09-28.csv',\n",
       " '2015-09-29.csv',\n",
       " '2015-09-30.csv',\n",
       " '2015-10-01.csv',\n",
       " '2015-10-02.csv',\n",
       " '2015-10-03.csv',\n",
       " '2015-10-04.csv',\n",
       " '2015-10-05.csv',\n",
       " '2015-10-06.csv',\n",
       " '2015-10-07.csv',\n",
       " '2015-10-08.csv',\n",
       " '2015-10-09.csv',\n",
       " '2015-10-10.csv',\n",
       " '2015-10-11.csv',\n",
       " '2015-10-12.csv',\n",
       " '2015-10-13.csv',\n",
       " '2015-10-14.csv',\n",
       " '2015-10-15.csv',\n",
       " '2015-10-16.csv',\n",
       " '2015-10-17.csv',\n",
       " '2015-10-18.csv',\n",
       " '2015-10-19.csv',\n",
       " '2015-10-20.csv',\n",
       " '2015-10-21.csv',\n",
       " '2015-10-22.csv',\n",
       " '2015-10-23.csv',\n",
       " '2015-10-24.csv',\n",
       " '2015-10-25.csv',\n",
       " '2015-10-26.csv',\n",
       " '2015-10-27.csv',\n",
       " '2015-10-28.csv',\n",
       " '2015-10-29.csv',\n",
       " '2015-10-30.csv',\n",
       " '2015-10-31.csv',\n",
       " '2015-11-01.csv',\n",
       " '2015-11-02.csv',\n",
       " '2015-11-03.csv',\n",
       " '2015-11-04.csv',\n",
       " '2015-11-05.csv',\n",
       " '2015-11-06.csv',\n",
       " '2015-11-07.csv',\n",
       " '2015-11-08.csv',\n",
       " '2015-11-09.csv',\n",
       " '2015-11-10.csv',\n",
       " '2015-11-11.csv',\n",
       " '2015-11-12.csv',\n",
       " '2015-11-13.csv',\n",
       " '2015-11-14.csv',\n",
       " '2015-11-15.csv',\n",
       " '2015-11-16.csv',\n",
       " '2015-11-17.csv',\n",
       " '2015-11-18.csv',\n",
       " '2015-11-19.csv',\n",
       " '2015-11-20.csv',\n",
       " '2015-11-21.csv',\n",
       " '2015-11-22.csv',\n",
       " '2015-11-23.csv',\n",
       " '2015-11-24.csv',\n",
       " '2015-11-25.csv',\n",
       " '2015-11-26.csv',\n",
       " '2015-11-27.csv',\n",
       " '2015-11-28.csv',\n",
       " '2015-11-29.csv',\n",
       " '2015-11-30.csv',\n",
       " '2015-12-01.csv',\n",
       " '2015-12-02.csv',\n",
       " '2015-12-03.csv',\n",
       " '2015-12-04.csv',\n",
       " '2015-12-05.csv',\n",
       " '2015-12-06.csv',\n",
       " '2015-12-07.csv',\n",
       " '2015-12-08.csv',\n",
       " '2015-12-09.csv',\n",
       " '2015-12-10.csv',\n",
       " '2015-12-11.csv',\n",
       " '2015-12-12.csv',\n",
       " '2015-12-13.csv',\n",
       " '2015-12-14.csv',\n",
       " '2015-12-15.csv',\n",
       " '2015-12-16.csv',\n",
       " '2015-12-17.csv',\n",
       " '2015-12-18.csv',\n",
       " '2015-12-19.csv',\n",
       " '2015-12-20.csv',\n",
       " '2015-12-21.csv',\n",
       " '2015-12-22.csv',\n",
       " '2015-12-23.csv',\n",
       " '2015-12-24.csv',\n",
       " '2015-12-25.csv',\n",
       " '2015-12-26.csv',\n",
       " '2015-12-27.csv',\n",
       " '2015-12-28.csv',\n",
       " '2015-12-29.csv',\n",
       " '2015-12-30.csv',\n",
       " '2016-01-03.csv',\n",
       " '2016-01-04.csv',\n",
       " '2016-01-05.csv',\n",
       " '2016-01-06.csv',\n",
       " '2016-01-07.csv',\n",
       " '2016-01-08.csv',\n",
       " '2016-01-09.csv',\n",
       " '2016-01-10.csv',\n",
       " '2016-01-11.csv',\n",
       " '2016-01-12.csv',\n",
       " '2016-01-13.csv',\n",
       " '2016-01-14.csv',\n",
       " '2016-01-15.csv',\n",
       " '2016-01-16.csv',\n",
       " '2016-01-17.csv',\n",
       " '2016-01-18.csv',\n",
       " '2016-01-19.csv',\n",
       " '2016-01-20.csv',\n",
       " '2016-01-21.csv',\n",
       " '2016-01-22.csv',\n",
       " '2016-01-23.csv',\n",
       " '2016-01-24.csv',\n",
       " '2016-01-25.csv',\n",
       " '2016-01-26.csv',\n",
       " '2016-01-27.csv',\n",
       " '2016-01-28.csv',\n",
       " '2016-01-29.csv',\n",
       " '2016-01-30.csv',\n",
       " '2016-01-31.csv',\n",
       " '2016-02-01.csv',\n",
       " '2016-02-02.csv',\n",
       " '2016-02-03.csv',\n",
       " '2016-02-04.csv',\n",
       " '2016-02-05.csv',\n",
       " '2016-02-06.csv',\n",
       " '2016-02-07.csv',\n",
       " '2016-02-08.csv',\n",
       " '2016-02-09.csv',\n",
       " '2016-02-10.csv',\n",
       " '2016-02-11.csv',\n",
       " '2016-02-12.csv',\n",
       " '2016-02-13.csv',\n",
       " '2016-02-14.csv',\n",
       " '2016-02-15.csv',\n",
       " '2016-02-16.csv',\n",
       " '2016-02-17.csv',\n",
       " '2016-02-18.csv',\n",
       " '2016-02-19.csv',\n",
       " '2016-02-20.csv',\n",
       " '2016-02-21.csv',\n",
       " '2016-02-22.csv',\n",
       " '2016-02-23.csv',\n",
       " '2016-02-24.csv',\n",
       " '2016-02-25.csv',\n",
       " '2016-02-26.csv',\n",
       " '2016-02-27.csv',\n",
       " '2016-02-28.csv',\n",
       " '2016-02-29.csv',\n",
       " '2016-03-01.csv',\n",
       " '2016-03-02.csv',\n",
       " '2016-03-03.csv',\n",
       " '2016-03-04.csv',\n",
       " '2016-03-05.csv',\n",
       " '2016-03-06.csv',\n",
       " '2016-03-07.csv',\n",
       " '2016-03-08.csv',\n",
       " '2016-03-09.csv',\n",
       " '2016-03-10.csv',\n",
       " '2016-03-11.csv',\n",
       " '2016-03-12.csv',\n",
       " '2016-03-13.csv',\n",
       " '2016-03-14.csv',\n",
       " '2016-03-15.csv',\n",
       " '2016-03-16.csv',\n",
       " '2016-03-17.csv',\n",
       " '2016-03-18.csv',\n",
       " '2016-03-19.csv',\n",
       " '2016-03-20.csv',\n",
       " '2016-03-21.csv',\n",
       " '2016-03-22.csv',\n",
       " '2016-03-23.csv',\n",
       " '2016-03-24.csv',\n",
       " '2016-03-25.csv',\n",
       " '2016-03-26.csv',\n",
       " '2016-03-27.csv',\n",
       " '2016-03-28.csv',\n",
       " '2016-03-29.csv',\n",
       " '2016-03-30.csv',\n",
       " '2016-03-31.csv',\n",
       " '2016-04-01.csv',\n",
       " '2016-04-02.csv',\n",
       " '2016-04-03.csv',\n",
       " '2016-04-04.csv',\n",
       " '2016-04-05.csv',\n",
       " '2016-04-06.csv',\n",
       " '2016-04-07.csv',\n",
       " '2016-04-08.csv',\n",
       " '2016-04-09.csv',\n",
       " '2016-04-10.csv',\n",
       " '2016-04-11.csv',\n",
       " '2016-04-12.csv',\n",
       " '2016-04-13.csv',\n",
       " '2016-04-14.csv',\n",
       " '2016-04-15.csv',\n",
       " '2016-04-16.csv',\n",
       " '2016-04-17.csv',\n",
       " '2016-04-18.csv',\n",
       " '2016-04-19.csv',\n",
       " '2016-04-20.csv',\n",
       " '2016-04-21.csv',\n",
       " '2016-04-22.csv',\n",
       " '2016-04-23.csv',\n",
       " '2016-04-24.csv',\n",
       " '2016-04-25.csv',\n",
       " '2016-04-26.csv',\n",
       " '2016-04-27.csv',\n",
       " '2016-04-28.csv',\n",
       " '2016-04-29.csv',\n",
       " '2016-04-30.csv',\n",
       " '2016-05-01.csv',\n",
       " '2016-05-02.csv',\n",
       " '2016-05-03.csv',\n",
       " '2016-05-04.csv',\n",
       " '2016-05-05.csv',\n",
       " '2016-05-06.csv',\n",
       " '2016-05-07.csv',\n",
       " '2016-05-08.csv',\n",
       " '2016-05-09.csv',\n",
       " '2016-05-10.csv',\n",
       " '2016-05-11.csv',\n",
       " '2016-05-12.csv',\n",
       " '2016-05-13.csv',\n",
       " '2016-05-14.csv',\n",
       " '2016-05-15.csv',\n",
       " '2016-05-16.csv',\n",
       " '2016-05-17.csv',\n",
       " '2016-05-18.csv',\n",
       " '2016-05-19.csv',\n",
       " '2016-05-20.csv',\n",
       " '2016-05-21.csv',\n",
       " '2016-05-22.csv',\n",
       " '2016-05-23.csv',\n",
       " '2016-05-24.csv',\n",
       " '2016-05-25.csv',\n",
       " '2016-05-26.csv',\n",
       " '2016-05-27.csv',\n",
       " '2016-05-28.csv',\n",
       " '2016-05-29.csv',\n",
       " '2016-05-30.csv',\n",
       " '2016-05-31.csv',\n",
       " '2016-06-01.csv',\n",
       " '2016-06-02.csv',\n",
       " '2016-06-03.csv',\n",
       " '2016-06-04.csv',\n",
       " '2016-06-05.csv',\n",
       " '2016-06-06.csv',\n",
       " '2016-06-07.csv',\n",
       " '2016-06-08.csv',\n",
       " '2016-06-09.csv',\n",
       " '2016-06-10.csv',\n",
       " '2016-06-11.csv',\n",
       " '2016-06-12.csv',\n",
       " '2016-06-13.csv',\n",
       " '2016-06-14.csv',\n",
       " '2016-06-15.csv',\n",
       " '2016-06-16.csv',\n",
       " '2016-06-17.csv',\n",
       " '2016-06-18.csv',\n",
       " '2016-06-19.csv',\n",
       " '2016-06-20.csv',\n",
       " '2016-06-21.csv',\n",
       " '2016-06-22.csv',\n",
       " '2016-06-23.csv',\n",
       " '2016-06-24.csv',\n",
       " '2016-06-25.csv',\n",
       " '2016-06-26.csv',\n",
       " '2016-06-27.csv',\n",
       " '2016-06-28.csv',\n",
       " '2016-06-29.csv',\n",
       " '2016-06-30.csv',\n",
       " '2016-07-01.csv',\n",
       " '2016-07-02.csv',\n",
       " '2016-07-03.csv',\n",
       " '2016-07-04.csv',\n",
       " '2016-07-05.csv',\n",
       " '2016-07-06.csv',\n",
       " '2016-07-07.csv',\n",
       " '2016-07-08.csv',\n",
       " '2016-07-09.csv',\n",
       " '2016-07-10.csv',\n",
       " '2016-07-11.csv',\n",
       " '2016-07-12.csv',\n",
       " '2016-07-13.csv',\n",
       " '2016-07-14.csv',\n",
       " '2016-07-15.csv',\n",
       " '2016-07-16.csv',\n",
       " '2016-07-17.csv',\n",
       " '2016-07-18.csv',\n",
       " '2016-07-19.csv',\n",
       " '2016-07-20.csv',\n",
       " '2016-07-21.csv',\n",
       " '2016-07-22.csv',\n",
       " '2016-07-23.csv',\n",
       " '2016-07-24.csv',\n",
       " '2016-07-25.csv',\n",
       " '2016-07-26.csv',\n",
       " '2016-07-27.csv',\n",
       " '2016-07-28.csv',\n",
       " '2016-07-29.csv',\n",
       " '2016-07-30.csv',\n",
       " '2016-07-31.csv',\n",
       " '2016-08-01.csv',\n",
       " '2016-08-02.csv',\n",
       " '2016-08-03.csv',\n",
       " '2016-08-04.csv',\n",
       " '2016-08-05.csv',\n",
       " '2016-08-06.csv',\n",
       " '2016-08-07.csv',\n",
       " '2016-08-08.csv',\n",
       " '2016-08-09.csv',\n",
       " '2016-08-10.csv',\n",
       " '2016-08-11.csv',\n",
       " '2016-08-12.csv',\n",
       " '2016-08-13.csv',\n",
       " '2016-08-14.csv',\n",
       " '2016-08-15.csv',\n",
       " '2016-08-16.csv',\n",
       " '2016-08-17.csv',\n",
       " '2016-08-18.csv',\n",
       " '2016-08-19.csv',\n",
       " '2016-08-20.csv',\n",
       " '2016-08-21.csv',\n",
       " '2016-08-22.csv',\n",
       " '2016-08-23.csv',\n",
       " '2016-08-24.csv',\n",
       " '2016-08-25.csv',\n",
       " '2016-08-26.csv',\n",
       " '2016-08-27.csv',\n",
       " '2016-08-28.csv',\n",
       " '2016-08-29.csv',\n",
       " '2016-08-30.csv',\n",
       " '2016-08-31.csv',\n",
       " '2016-09-01.csv',\n",
       " '2016-09-02.csv',\n",
       " '2016-09-03.csv',\n",
       " '2016-09-04.csv',\n",
       " '2016-09-05.csv',\n",
       " '2016-09-06.csv',\n",
       " '2016-09-07.csv',\n",
       " '2016-09-08.csv',\n",
       " '2016-09-09.csv',\n",
       " '2016-09-10.csv',\n",
       " '2016-09-11.csv',\n",
       " '2016-09-12.csv',\n",
       " '2016-09-13.csv',\n",
       " '2016-09-14.csv',\n",
       " '2016-09-15.csv',\n",
       " '2016-09-16.csv',\n",
       " '2016-09-17.csv',\n",
       " '2016-09-18.csv',\n",
       " '2016-09-19.csv',\n",
       " '2016-09-20.csv',\n",
       " '2016-09-21.csv',\n",
       " '2016-09-22.csv',\n",
       " '2016-09-23.csv',\n",
       " '2016-09-24.csv',\n",
       " '2016-09-25.csv',\n",
       " '2016-09-26.csv',\n",
       " '2016-09-27.csv',\n",
       " '2016-09-28.csv',\n",
       " '2016-09-29.csv',\n",
       " '2016-09-30.csv',\n",
       " '2016-10-01.csv',\n",
       " '2016-10-02.csv',\n",
       " '2016-10-03.csv',\n",
       " '2016-10-04.csv',\n",
       " '2016-10-05.csv',\n",
       " '2016-10-06.csv',\n",
       " '2016-10-07.csv',\n",
       " '2016-10-08.csv',\n",
       " '2016-10-09.csv',\n",
       " '2016-10-10.csv',\n",
       " '2016-10-11.csv',\n",
       " '2016-10-12.csv',\n",
       " '2016-10-13.csv',\n",
       " '2016-10-14.csv',\n",
       " '2016-10-15.csv',\n",
       " '2016-10-16.csv',\n",
       " '2016-10-17.csv',\n",
       " '2016-10-18.csv',\n",
       " '2016-10-19.csv',\n",
       " '2016-10-20.csv',\n",
       " '2016-10-21.csv',\n",
       " '2016-10-22.csv',\n",
       " '2016-10-23.csv',\n",
       " '2016-10-24.csv',\n",
       " '2016-10-25.csv',\n",
       " '2016-10-26.csv',\n",
       " '2016-10-27.csv',\n",
       " '2016-10-28.csv',\n",
       " '2016-10-29.csv',\n",
       " '2016-10-30.csv',\n",
       " '2016-10-31.csv',\n",
       " '2016-11-01.csv',\n",
       " '2016-11-02.csv',\n",
       " '2016-11-03.csv',\n",
       " '2016-11-04.csv',\n",
       " '2016-11-05.csv',\n",
       " '2016-11-06.csv',\n",
       " '2016-11-07.csv',\n",
       " '2016-11-08.csv',\n",
       " '2016-11-09.csv',\n",
       " '2016-11-10.csv',\n",
       " '2016-11-11.csv',\n",
       " '2016-11-12.csv',\n",
       " '2016-11-13.csv',\n",
       " '2016-11-14.csv',\n",
       " '2016-11-15.csv',\n",
       " '2016-11-16.csv',\n",
       " '2016-11-17.csv',\n",
       " '2016-11-18.csv',\n",
       " '2016-11-19.csv',\n",
       " '2016-11-20.csv',\n",
       " '2016-11-21.csv',\n",
       " '2016-11-22.csv',\n",
       " '2016-11-23.csv',\n",
       " '2016-11-24.csv',\n",
       " '2016-11-25.csv',\n",
       " '2016-11-26.csv',\n",
       " '2016-11-27.csv',\n",
       " '2016-11-28.csv',\n",
       " '2016-11-29.csv',\n",
       " '2016-11-30.csv',\n",
       " '2016-12-01.csv',\n",
       " '2016-12-02.csv',\n",
       " '2016-12-03.csv',\n",
       " '2016-12-04.csv',\n",
       " '2016-12-05.csv',\n",
       " '2016-12-06.csv',\n",
       " '2016-12-07.csv',\n",
       " '2016-12-08.csv',\n",
       " '2016-12-09.csv',\n",
       " '2016-12-10.csv',\n",
       " '2016-12-11.csv',\n",
       " '2016-12-12.csv',\n",
       " '2016-12-13.csv',\n",
       " '2016-12-14.csv',\n",
       " '2016-12-15.csv',\n",
       " '2016-12-16.csv',\n",
       " '2016-12-17.csv',\n",
       " '2016-12-18.csv',\n",
       " '2016-12-19.csv',\n",
       " '2016-12-20.csv',\n",
       " '2016-12-21.csv',\n",
       " '2016-12-22.csv',\n",
       " '2016-12-23.csv',\n",
       " '2016-12-24.csv',\n",
       " '2016-12-25.csv',\n",
       " '2016-12-26.csv',\n",
       " '2016-12-27.csv',\n",
       " '2016-12-28.csv',\n",
       " '2016-12-29.csv',\n",
       " '2016-12-30.csv',\n",
       " '2016-12-31.csv',\n",
       " '2017-01-01.csv',\n",
       " '2017-01-02.csv',\n",
       " '2017-01-03.csv',\n",
       " '2017-01-04.csv',\n",
       " '2017-01-05.csv',\n",
       " '2017-01-06.csv',\n",
       " '2017-01-07.csv',\n",
       " '2017-01-08.csv',\n",
       " '2017-01-09.csv',\n",
       " '2017-01-10.csv',\n",
       " '2017-01-11.csv',\n",
       " '2017-01-12.csv',\n",
       " '2017-01-13.csv',\n",
       " '2017-01-14.csv',\n",
       " '2017-01-15.csv',\n",
       " '2017-01-16.csv',\n",
       " '2017-01-17.csv',\n",
       " '2017-01-18.csv',\n",
       " '2017-01-19.csv',\n",
       " '2017-01-20.csv',\n",
       " '2017-01-21.csv',\n",
       " '2017-01-22.csv',\n",
       " '2017-01-23.csv',\n",
       " '2017-01-24.csv',\n",
       " '2017-01-25.csv',\n",
       " '2017-01-26.csv',\n",
       " '2017-01-27.csv',\n",
       " '2017-01-28.csv',\n",
       " '2017-01-29.csv',\n",
       " '2017-01-30.csv',\n",
       " '2017-01-31.csv',\n",
       " '2017-02-01.csv',\n",
       " '2017-02-02.csv',\n",
       " '2017-02-03.csv',\n",
       " '2017-02-04.csv',\n",
       " '2017-02-05.csv',\n",
       " '2017-02-06.csv',\n",
       " '2017-02-07.csv',\n",
       " '2017-02-08.csv',\n",
       " '2017-02-09.csv',\n",
       " '2017-02-10.csv',\n",
       " '2017-02-11.csv',\n",
       " '2017-02-12.csv',\n",
       " '2017-02-13.csv',\n",
       " '2017-02-14.csv',\n",
       " '2017-02-15.csv',\n",
       " '2017-02-16.csv',\n",
       " '2017-02-17.csv',\n",
       " '2017-02-18.csv',\n",
       " '2017-02-19.csv',\n",
       " '2017-02-20.csv',\n",
       " '2017-02-21.csv',\n",
       " '2017-02-22.csv',\n",
       " '2017-02-23.csv',\n",
       " '2017-02-24.csv',\n",
       " '2017-02-25.csv',\n",
       " '2017-02-26.csv',\n",
       " '2017-02-27.csv',\n",
       " '2017-02-28.csv',\n",
       " '2017-03-01.csv',\n",
       " '2017-03-02.csv',\n",
       " '2017-03-03.csv',\n",
       " '2017-03-04.csv',\n",
       " '2017-03-05.csv',\n",
       " '2017-03-06.csv',\n",
       " '2017-03-07.csv',\n",
       " '2017-03-08.csv',\n",
       " '2017-03-09.csv',\n",
       " '2017-03-10.csv',\n",
       " '2017-03-11.csv',\n",
       " '2017-03-12.csv',\n",
       " '2017-03-13.csv',\n",
       " '2017-03-14.csv',\n",
       " '2017-03-15.csv',\n",
       " '2017-03-16.csv',\n",
       " '2017-03-17.csv',\n",
       " '2017-03-18.csv',\n",
       " '2017-03-19.csv',\n",
       " '2017-03-20.csv',\n",
       " '2017-03-21.csv',\n",
       " '2017-03-22.csv',\n",
       " '2017-03-23.csv',\n",
       " '2017-03-24.csv',\n",
       " '2017-03-25.csv',\n",
       " '2017-03-26.csv',\n",
       " '2017-03-27.csv',\n",
       " '2017-03-28.csv',\n",
       " '2017-03-29.csv',\n",
       " '2017-03-30.csv',\n",
       " '2017-03-31.csv',\n",
       " '2017-04-01.csv',\n",
       " '2017-04-02.csv',\n",
       " '2017-04-03.csv',\n",
       " '2017-04-04.csv',\n",
       " '2017-04-05.csv',\n",
       " '2017-04-06.csv',\n",
       " '2017-04-07.csv',\n",
       " '2017-04-08.csv',\n",
       " '2017-04-09.csv',\n",
       " '2017-04-10.csv',\n",
       " '2017-04-11.csv',\n",
       " '2017-04-12.csv',\n",
       " '2017-04-13.csv',\n",
       " '2017-04-14.csv',\n",
       " '2017-04-15.csv',\n",
       " '2017-04-16.csv',\n",
       " '2017-04-17.csv',\n",
       " '2017-04-18.csv',\n",
       " '2017-04-19.csv',\n",
       " '2017-04-20.csv',\n",
       " '2017-04-21.csv',\n",
       " '2017-04-22.csv',\n",
       " '2017-04-23.csv',\n",
       " '2017-04-24.csv',\n",
       " '2017-04-25.csv',\n",
       " '2017-04-26.csv',\n",
       " '2017-04-27.csv',\n",
       " '2017-04-28.csv',\n",
       " '2017-04-29.csv',\n",
       " '2017-04-30.csv',\n",
       " '2017-05-01.csv',\n",
       " '2017-05-02.csv',\n",
       " '2017-05-03.csv',\n",
       " '2017-05-04.csv',\n",
       " '2017-05-05.csv',\n",
       " '2017-05-06.csv',\n",
       " '2017-05-07.csv',\n",
       " '2017-05-08.csv',\n",
       " '2017-05-09.csv',\n",
       " '2017-05-10.csv',\n",
       " '2017-05-11.csv',\n",
       " '2017-05-12.csv',\n",
       " '2017-05-13.csv',\n",
       " '2017-05-14.csv',\n",
       " '2017-05-15.csv',\n",
       " '2017-05-16.csv',\n",
       " '2017-05-17.csv',\n",
       " '2017-05-18.csv',\n",
       " '2017-05-19.csv',\n",
       " '2017-05-20.csv',\n",
       " '2017-05-21.csv',\n",
       " '2017-05-22.csv',\n",
       " '2017-05-23.csv',\n",
       " '2017-05-24.csv',\n",
       " '2017-05-25.csv',\n",
       " '2017-05-26.csv',\n",
       " '2017-05-27.csv',\n",
       " '2017-05-28.csv',\n",
       " '2017-05-29.csv',\n",
       " '2017-05-30.csv',\n",
       " '2017-05-31.csv',\n",
       " '2017-06-01.csv',\n",
       " '2017-06-02.csv',\n",
       " '2017-06-03.csv',\n",
       " '2017-06-04.csv',\n",
       " '2017-06-05.csv',\n",
       " '2017-06-06.csv',\n",
       " '2017-06-07.csv',\n",
       " '2017-06-08.csv',\n",
       " '2017-06-09.csv',\n",
       " '2017-06-10.csv',\n",
       " '2017-06-11.csv',\n",
       " '2017-06-12.csv',\n",
       " '2017-06-13.csv',\n",
       " '2017-06-14.csv',\n",
       " '2017-06-15.csv',\n",
       " '2017-06-16.csv',\n",
       " '2017-06-17.csv',\n",
       " '2017-06-18.csv',\n",
       " '2017-06-19.csv',\n",
       " '2017-06-20.csv',\n",
       " '2017-06-21.csv',\n",
       " '2017-06-22.csv',\n",
       " '2017-06-23.csv',\n",
       " '2017-06-24.csv',\n",
       " '2017-06-25.csv',\n",
       " '2017-06-26.csv',\n",
       " '2017-06-27.csv',\n",
       " '2017-06-28.csv',\n",
       " '2017-06-29.csv',\n",
       " '2017-06-30.csv',\n",
       " '2017-07-01.csv',\n",
       " '2017-07-02.csv',\n",
       " '2017-07-03.csv',\n",
       " '2017-07-04.csv',\n",
       " '2017-07-05.csv',\n",
       " '2017-07-06.csv',\n",
       " '2017-07-07.csv',\n",
       " '2017-07-08.csv',\n",
       " '2017-07-09.csv',\n",
       " '2017-07-10.csv',\n",
       " '2017-07-11.csv',\n",
       " '2017-07-12.csv',\n",
       " '2017-07-13.csv',\n",
       " '2017-07-14.csv',\n",
       " '2017-07-15.csv',\n",
       " '2017-07-16.csv',\n",
       " '2017-07-17.csv',\n",
       " '2017-07-18.csv',\n",
       " '2017-07-19.csv',\n",
       " '2017-07-20.csv',\n",
       " '2017-07-21.csv',\n",
       " '2017-07-22.csv',\n",
       " '2017-07-23.csv',\n",
       " '2017-07-24.csv',\n",
       " '2017-07-25.csv',\n",
       " '2017-07-26.csv',\n",
       " '2017-07-27.csv',\n",
       " '2017-07-28.csv',\n",
       " '2017-07-29.csv',\n",
       " '2017-07-30.csv',\n",
       " '2017-07-31.csv',\n",
       " '2017-08-01.csv',\n",
       " '2017-08-02.csv',\n",
       " '2017-08-03.csv',\n",
       " '2017-08-04.csv',\n",
       " '2017-08-05.csv',\n",
       " '2017-08-06.csv',\n",
       " '2017-08-07.csv',\n",
       " '2017-08-08.csv',\n",
       " '2017-08-09.csv',\n",
       " '2017-08-10.csv',\n",
       " '2017-08-11.csv',\n",
       " '2017-08-12.csv',\n",
       " '2017-08-13.csv',\n",
       " '2017-08-14.csv',\n",
       " '2017-08-15.csv',\n",
       " '2017-08-16.csv',\n",
       " '2017-08-17.csv',\n",
       " '2017-08-18.csv',\n",
       " '2017-08-19.csv',\n",
       " '2017-08-20.csv',\n",
       " '2017-08-21.csv',\n",
       " '2017-08-22.csv',\n",
       " '2017-08-23.csv',\n",
       " '2017-08-24.csv',\n",
       " '2017-08-25.csv',\n",
       " '2017-08-26.csv',\n",
       " '2017-08-27.csv',\n",
       " '2017-08-28.csv',\n",
       " '2017-08-29.csv',\n",
       " '2017-08-30.csv',\n",
       " '2017-08-31.csv',\n",
       " '2017-09-01.csv',\n",
       " '2017-09-02.csv',\n",
       " '2017-09-03.csv',\n",
       " '2017-09-04.csv',\n",
       " '2017-09-05.csv',\n",
       " '2017-09-06.csv',\n",
       " '2017-09-07.csv',\n",
       " '2017-09-08.csv',\n",
       " '2017-09-09.csv',\n",
       " '2017-09-10.csv',\n",
       " '2017-09-11.csv',\n",
       " '2017-09-12.csv',\n",
       " '2017-09-13.csv',\n",
       " '2017-09-14.csv',\n",
       " '2017-09-15.csv',\n",
       " '2017-09-16.csv',\n",
       " '2017-09-17.csv',\n",
       " '2017-09-18.csv',\n",
       " '2017-09-19.csv',\n",
       " '2017-09-20.csv',\n",
       " '2017-09-21.csv',\n",
       " '2017-09-22.csv',\n",
       " '2017-09-23.csv',\n",
       " '2017-09-24.csv',\n",
       " '2017-09-25.csv',\n",
       " '2017-09-26.csv',\n",
       " '2017-09-27.csv',\n",
       " '2017-09-28.csv',\n",
       " '2017-09-29.csv',\n",
       " '2017-09-30.csv',\n",
       " '2017-10-01.csv',\n",
       " '2017-10-02.csv',\n",
       " '2017-10-03.csv',\n",
       " '2017-10-04.csv',\n",
       " '2017-10-05.csv',\n",
       " '2017-10-06.csv',\n",
       " '2017-10-07.csv',\n",
       " '2017-10-08.csv',\n",
       " '2017-10-09.csv',\n",
       " '2017-10-10.csv',\n",
       " '2017-10-11.csv',\n",
       " '2017-10-12.csv',\n",
       " '2017-10-13.csv',\n",
       " '2017-10-14.csv',\n",
       " '2017-10-15.csv',\n",
       " '2017-10-16.csv',\n",
       " '2017-10-17.csv',\n",
       " '2017-10-18.csv',\n",
       " '2017-10-19.csv',\n",
       " '2017-10-20.csv',\n",
       " '2017-10-21.csv',\n",
       " '2017-10-22.csv',\n",
       " '2017-10-23.csv',\n",
       " '2017-10-24.csv',\n",
       " '2017-10-25.csv',\n",
       " '2017-10-26.csv',\n",
       " '2017-10-27.csv',\n",
       " '2017-10-28.csv',\n",
       " '2017-10-29.csv',\n",
       " '2017-10-30.csv',\n",
       " '2017-10-31.csv',\n",
       " '2017-11-01.csv',\n",
       " '2017-11-02.csv',\n",
       " '2017-11-03.csv',\n",
       " '2017-11-04.csv',\n",
       " '2017-11-05.csv',\n",
       " '2017-11-06.csv',\n",
       " '2017-11-07.csv',\n",
       " '2017-11-08.csv',\n",
       " '2017-11-09.csv',\n",
       " '2017-11-10.csv',\n",
       " '2017-11-11.csv',\n",
       " '2017-11-12.csv',\n",
       " '2017-11-13.csv',\n",
       " '2017-11-14.csv',\n",
       " '2017-11-15.csv',\n",
       " '2017-11-16.csv',\n",
       " '2017-11-17.csv',\n",
       " '2017-11-18.csv',\n",
       " '2017-11-19.csv',\n",
       " '2017-11-20.csv',\n",
       " '2017-11-21.csv',\n",
       " '2017-11-22.csv',\n",
       " '2017-11-23.csv',\n",
       " '2017-11-24.csv',\n",
       " '2017-11-25.csv',\n",
       " '2017-11-26.csv',\n",
       " '2017-11-27.csv',\n",
       " '2017-11-28.csv',\n",
       " '2017-11-29.csv',\n",
       " '2017-11-30.csv',\n",
       " '2017-12-01.csv',\n",
       " '2017-12-02.csv',\n",
       " '2017-12-03.csv',\n",
       " '2017-12-04.csv',\n",
       " '2017-12-05.csv',\n",
       " '2017-12-06.csv',\n",
       " '2017-12-07.csv',\n",
       " '2017-12-08.csv',\n",
       " '2017-12-09.csv',\n",
       " '2017-12-10.csv',\n",
       " 'index.html']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket = \"openaq-data\"\n",
    "openaq_data = s3_resource.Bucket(bucket)\n",
    "keys = []\n",
    "for file in openaq_data.objects.filter():\n",
    "    keys.append(file.key)\n",
    "keys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now handling date: 2015-11-21.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-11-22.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-11-23.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-11-24.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-11-25.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-11-26.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-11-27.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-11-28.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-11-29.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-11-30.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-01.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-02.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-03.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-04.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-05.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-06.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-07.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-08.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-09.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-10.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-11.csv\n",
      "Number of new observations added to open_aq_locations: 7\n",
      "Completed up until index: 20\n",
      "Now handling date: 2015-12-12.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-13.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-14.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-15.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-16.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-17.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-18.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-19.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-20.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-21.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-22.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2015-12-23.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2015-12-24.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-25.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-26.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-27.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-28.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-29.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2015-12-30.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-03.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-04.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-05.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-06.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-07.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-08.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-09.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-10.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-11.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-12.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-13.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-14.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-15.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-01-16.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-17.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-18.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-19.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-20.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-21.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-22.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-23.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-24.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-25.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-26.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-27.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-28.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-29.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-30.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-01-31.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-01.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-02.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-03.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-04.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-05.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-06.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-07.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-08.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-09.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-10.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-11.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-12.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-13.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-14.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-15.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-16.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-17.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-18.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-19.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-20.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-21.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-22.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-02-23.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-02-24.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-25.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-26.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-27.csv\n",
      "Number of new observations added to open_aq_locations: 11\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-02-28.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-02-29.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-01.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-03-02.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-03-03.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-03-04.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-05.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-03-06.csv\n",
      "Number of new observations added to open_aq_locations: 257\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Completed up until index: 160\n",
      "Completed up until index: 180\n",
      "Completed up until index: 200\n",
      "Completed up until index: 220\n",
      "Completed up until index: 240\n",
      "Completed up until index: 260\n",
      "Now handling date: 2016-03-07.csv\n",
      "Number of new observations added to open_aq_locations: 17\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-08.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-03-09.csv\n",
      "Number of new observations added to open_aq_locations: 0\n",
      "{\"error\":[\"syntax error at end of input\"]}\n",
      "Empty DataFrame\n",
      "Columns: [location, city, country, latitude, longitude]\n",
      "Index: []\n",
      "Now handling date: 2016-03-10.csv\n",
      "Number of new observations added to open_aq_locations: 63\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Now handling date: 2016-03-11.csv\n",
      "Number of new observations added to open_aq_locations: 17\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-12.csv\n",
      "Number of new observations added to open_aq_locations: 6\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-13.csv\n",
      "Number of new observations added to open_aq_locations: 18\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-14.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-15.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-16.csv\n",
      "Number of new observations added to open_aq_locations: 8\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-17.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-18.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-19.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-20.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-21.csv\n",
      "Number of new observations added to open_aq_locations: 11\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-22.csv\n",
      "Number of new observations added to open_aq_locations: 9\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-23.csv\n",
      "Number of new observations added to open_aq_locations: 16\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-24.csv\n",
      "Number of new observations added to open_aq_locations: 8\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-25.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-26.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-27.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-28.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-29.csv\n",
      "Number of new observations added to open_aq_locations: 9\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-03-30.csv\n",
      "Number of new observations added to open_aq_locations: 24\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2016-03-31.csv\n",
      "Number of new observations added to open_aq_locations: 12\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-01.csv\n",
      "Number of new observations added to open_aq_locations: 54\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Now handling date: 2016-04-02.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-03.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-04.csv\n",
      "Number of new observations added to open_aq_locations: 27\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Now handling date: 2016-04-05.csv\n",
      "Number of new observations added to open_aq_locations: 18\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-06.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-07.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-08.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-09.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-10.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-11.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-12.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-13.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-14.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-15.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-16.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-17.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-18.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-19.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-20.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-21.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-22.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-23.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-24.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-25.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-26.csv\n",
      "Number of new observations added to open_aq_locations: 13\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-27.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-28.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-29.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-04-30.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-01.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-02.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-03.csv\n",
      "Number of new observations added to open_aq_locations: 4\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-04.csv\n",
      "Number of new observations added to open_aq_locations: 5\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-05.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-06.csv\n",
      "Number of new observations added to open_aq_locations: 7\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-07.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-08.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-09.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-10.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-11.csv\n",
      "Number of new observations added to open_aq_locations: 3\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-12.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-13.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-14.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-15.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-16.csv\n",
      "Number of new observations added to open_aq_locations: 2\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-17.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-350-44d1a1265560>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Now handling date:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://openaq-data.s3.amazonaws.com/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         kwargs = {\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_infer_compression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     filepath_or_buffer, _, compression = get_filepath_or_buffer(\n\u001b[0;32m--> 392\u001b[0;31m         filepath_or_buffer, encoding, compression)\n\u001b[0m\u001b[1;32m    393\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compression'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;31m# Override compression based on Content-Encoding header\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gzip'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m                     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAXAMOUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1002\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1003\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \"\"\"\n\u001b[1;32m    624\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 135:310 comes from the code snippet below, to restart code and add in date to output of each loop\n",
    "for csv in keys[135:310]:\n",
    "    if csv[-3:] == \"csv\":\n",
    "        print(\"Now handling date:\", csv)\n",
    "        url = \"https://openaq-data.s3.amazonaws.com/\"+csv\n",
    "        data = pd.read_csv(url)\n",
    "        \n",
    "        kwargs = {\n",
    "            \"data_df\":data,\n",
    "            \"target_table_name\":\"open_aq_locations\",\n",
    "            \"cols_and_types\":cols_and_types_locations,\n",
    "            \"cols_with_apostrophes\":[\"location\", \"city\",\"country\"],\n",
    "            \"float_cols\":[\"latitude\", \"longitude\"],\n",
    "            \"precision\":6\n",
    "        }\n",
    "\n",
    "        update_table_without_duplicates(**kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now handling date: 2016-05-16.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-17.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-18.csv\n",
      "Number of new observations added to open_aq_locations: 1\n",
      "Completed up until index: 20\n",
      "Now handling date: 2016-05-19.csv\n"
     ]
    }
   ],
   "source": [
    "# 310 comes from the code snippet below, to restart code and add in date to output of each loop\n",
    "for csv in keys[309:]:\n",
    "    if csv[-3:] == \"csv\":\n",
    "        print(\"Now handling date:\", csv)\n",
    "        url = \"https://openaq-data.s3.amazonaws.com/\"+csv\n",
    "        data = pd.read_csv(url)\n",
    "        \n",
    "        kwargs = {\n",
    "            \"data_df\":data,\n",
    "            \"target_table_name\":\"open_aq_locations\",\n",
    "            \"cols_and_types\":cols_and_types_locations,\n",
    "            \"cols_with_apostrophes\":[\"location\", \"city\",\"country\"],\n",
    "            \"float_cols\":[\"latitude\", \"longitude\"],\n",
    "            \"precision\":6\n",
    "        }\n",
    "\n",
    "        update_table_without_duplicates(**kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([310]),)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I wanted to add in a date display to the loop above\n",
    "# Used the code below to figure where I had stopped previously\n",
    "np.where(np.array(keys)==csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read open_aq_locations table from Carto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A list of all locations ever reporting to the OpenAQ network:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Escuela E-10</td>\n",
       "      <td>Tocopilla</td>\n",
       "      <td>CL</td>\n",
       "      <td>-22.085519</td>\n",
       "      <td>-70.188683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chiu Chiu</td>\n",
       "      <td>Calama</td>\n",
       "      <td>CL</td>\n",
       "      <td>-22.342264</td>\n",
       "      <td>-68.650897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Santa Margarita</td>\n",
       "      <td>Catemu</td>\n",
       "      <td>CL</td>\n",
       "      <td>-32.776573</td>\n",
       "      <td>-70.938144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nueva Libertad</td>\n",
       "      <td>Talcahuano</td>\n",
       "      <td>CL</td>\n",
       "      <td>-36.735998</td>\n",
       "      <td>-73.118693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lo Campo</td>\n",
       "      <td>Panquehue</td>\n",
       "      <td>CL</td>\n",
       "      <td>-32.797715</td>\n",
       "      <td>-70.898037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Coronel Sur</td>\n",
       "      <td>Coronel</td>\n",
       "      <td>CL</td>\n",
       "      <td>-37.031702</td>\n",
       "      <td>-73.138689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Catemu</td>\n",
       "      <td>Catemu</td>\n",
       "      <td>CL</td>\n",
       "      <td>-32.779208</td>\n",
       "      <td>-70.959114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Calabozo</td>\n",
       "      <td>Coronel</td>\n",
       "      <td>CL</td>\n",
       "      <td>-36.996431</td>\n",
       "      <td>-73.115805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Romeral</td>\n",
       "      <td>Hijuelas</td>\n",
       "      <td>CL</td>\n",
       "      <td>-32.823956</td>\n",
       "      <td>-71.006441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lilla Essingen (E4/E20)</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>59.325519</td>\n",
       "      <td>18.003961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>E4/E20 Lilla Essingen</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>59.325519</td>\n",
       "      <td>18.003961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>E4 Sollentuna Hggvik</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>59.443539</td>\n",
       "      <td>17.922361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hgelbyleden Botkyrka</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>59.237058</td>\n",
       "      <td>17.838332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sveavgen</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>59.345161</td>\n",
       "      <td>18.054282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Estacin Centro</td>\n",
       "      <td>Calama</td>\n",
       "      <td>CL</td>\n",
       "      <td>-22.462145</td>\n",
       "      <td>-68.928062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Gvle Sdra Kungsgatan</td>\n",
       "      <td>Gvle</td>\n",
       "      <td>SE</td>\n",
       "      <td>60.671552</td>\n",
       "      <td>17.146915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Hornsgatan</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>59.317132</td>\n",
       "      <td>18.048787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Folkungagatan</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>59.314624</td>\n",
       "      <td>18.075856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Norrlandsgatan</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>59.336356</td>\n",
       "      <td>18.070626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sdertlje Turingegatan</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>59.198124</td>\n",
       "      <td>17.621087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Uppsala Kungsgatan</td>\n",
       "      <td>Uppsala</td>\n",
       "      <td>SE</td>\n",
       "      <td>59.859530</td>\n",
       "      <td>17.642484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Complejo Deportivo 23 de Marzo</td>\n",
       "      <td>Calama</td>\n",
       "      <td>CL</td>\n",
       "      <td>-22.460271</td>\n",
       "      <td>-68.937707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Colegio Pedro Vergara Keller</td>\n",
       "      <td>Calama</td>\n",
       "      <td>CL</td>\n",
       "      <td>-22.442839</td>\n",
       "      <td>-68.932546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Armutlu-MTHM</td>\n",
       "      <td>Yalova</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.529350</td>\n",
       "      <td>28.784590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Kltr Park-MTHM</td>\n",
       "      <td>Bursa</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.195720</td>\n",
       "      <td>29.045880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Sultanbeyli-MTHM</td>\n",
       "      <td>stanbul</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.984470</td>\n",
       "      <td>29.268810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>erkezky-MTHM</td>\n",
       "      <td>Tekirda</td>\n",
       "      <td>TR</td>\n",
       "      <td>41.318350</td>\n",
       "      <td>27.980180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Erdek-MTHM</td>\n",
       "      <td>Balkesir</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.489720</td>\n",
       "      <td>27.978610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Beyazt Cad.-MTHM</td>\n",
       "      <td>Bursa</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.185650</td>\n",
       "      <td>29.080490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Uluda niv.-MTHM</td>\n",
       "      <td>Bursa</td>\n",
       "      <td>TR</td>\n",
       "      <td>40.223370</td>\n",
       "      <td>28.871540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8216</th>\n",
       "      <td>Calabozo</td>\n",
       "      <td>Calabozo</td>\n",
       "      <td>CL</td>\n",
       "      <td>-36.996431</td>\n",
       "      <td>-73.115805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8217</th>\n",
       "      <td>V_VIEW</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.073200</td>\n",
       "      <td>-80.338600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8218</th>\n",
       "      <td>White Pine</td>\n",
       "      <td>Boise City-Nampa</td>\n",
       "      <td>US</td>\n",
       "      <td>43.577603</td>\n",
       "      <td>-116.178156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8219</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8220</th>\n",
       "      <td>Portland - Spangler</td>\n",
       "      <td>Portland-Vancouver-Beaverton</td>\n",
       "      <td>US</td>\n",
       "      <td>45.259280</td>\n",
       "      <td>-122.588151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8221</th>\n",
       "      <td>Talent - Rapp Lane</td>\n",
       "      <td>Medford</td>\n",
       "      <td>US</td>\n",
       "      <td>42.229891</td>\n",
       "      <td>-122.787700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8222</th>\n",
       "      <td>Catao 40</td>\n",
       "      <td>CATANO</td>\n",
       "      <td>US</td>\n",
       "      <td>18.428388</td>\n",
       "      <td>-66.141657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8223</th>\n",
       "      <td>Hermiston - Municipa</td>\n",
       "      <td>Pendleton-Hermiston</td>\n",
       "      <td>US</td>\n",
       "      <td>45.828968</td>\n",
       "      <td>-119.262991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8224</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8225</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8226</th>\n",
       "      <td>Saginaw - Delight Va</td>\n",
       "      <td>Eugene-Springfield</td>\n",
       "      <td>US</td>\n",
       "      <td>43.834470</td>\n",
       "      <td>-123.035375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8227</th>\n",
       "      <td>Inpesca</td>\n",
       "      <td>Inpesca</td>\n",
       "      <td>CL</td>\n",
       "      <td>-36.737202</td>\n",
       "      <td>-73.104427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8228</th>\n",
       "      <td>Flin Flon</td>\n",
       "      <td>MANITOBA</td>\n",
       "      <td>CA</td>\n",
       "      <td>54.765000</td>\n",
       "      <td>-101.875300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8229</th>\n",
       "      <td>Brandon</td>\n",
       "      <td>MANITOBA</td>\n",
       "      <td>CA</td>\n",
       "      <td>49.842200</td>\n",
       "      <td>-99.918900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8230</th>\n",
       "      <td>Winnipeg_Ellens</td>\n",
       "      <td>MANITOBA</td>\n",
       "      <td>CA</td>\n",
       "      <td>49.948900</td>\n",
       "      <td>-97.396400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8231</th>\n",
       "      <td>Winnipeg_Scotia</td>\n",
       "      <td>MANITOBA</td>\n",
       "      <td>CA</td>\n",
       "      <td>49.931900</td>\n",
       "      <td>-96.863100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8232</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8233</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8234</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8235</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8236</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8237</th>\n",
       "      <td>POMPANO_BEACH</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.290600</td>\n",
       "      <td>-80.096900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8238</th>\n",
       "      <td>DANIA_BEACH</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.086400</td>\n",
       "      <td>-80.111400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8239</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8240</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8241</th>\n",
       "      <td>San Juan de Aragn</td>\n",
       "      <td>DISTRITO FEDERAL</td>\n",
       "      <td>MX</td>\n",
       "      <td>19.452500</td>\n",
       "      <td>-99.086000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8242</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8243</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8244</th>\n",
       "      <td>nan</td>\n",
       "      <td>Miami-Fort Lauderdale-Miami Beach</td>\n",
       "      <td>US</td>\n",
       "      <td>26.593808</td>\n",
       "      <td>-80.058917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8245</th>\n",
       "      <td>La Serena</td>\n",
       "      <td>La Serena</td>\n",
       "      <td>CL</td>\n",
       "      <td>-29.933007</td>\n",
       "      <td>-71.261966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8246 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            location                               city  \\\n",
       "0                       Escuela E-10                          Tocopilla   \n",
       "1                          Chiu Chiu                             Calama   \n",
       "2                    Santa Margarita                             Catemu   \n",
       "3                     Nueva Libertad                         Talcahuano   \n",
       "4                           Lo Campo                          Panquehue   \n",
       "5                        Coronel Sur                            Coronel   \n",
       "6                             Catemu                             Catemu   \n",
       "7                           Calabozo                            Coronel   \n",
       "8                            Romeral                           Hijuelas   \n",
       "9            Lilla Essingen (E4/E20)                          Stockholm   \n",
       "10             E4/E20 Lilla Essingen                          Stockholm   \n",
       "11             E4 Sollentuna Hggvik                          Stockholm   \n",
       "12             Hgelbyleden Botkyrka                          Stockholm   \n",
       "13                         Sveavgen                          Stockholm   \n",
       "14                   Estacin Centro                             Calama   \n",
       "15            Gvle Sdra Kungsgatan                              Gvle   \n",
       "16                        Hornsgatan                          Stockholm   \n",
       "17                     Folkungagatan                          Stockholm   \n",
       "18                    Norrlandsgatan                          Stockholm   \n",
       "19           Sdertlje Turingegatan                          Stockholm   \n",
       "20                Uppsala Kungsgatan                            Uppsala   \n",
       "21    Complejo Deportivo 23 de Marzo                             Calama   \n",
       "22      Colegio Pedro Vergara Keller                             Calama   \n",
       "23                      Armutlu-MTHM                             Yalova   \n",
       "24                  Kltr Park-MTHM                              Bursa   \n",
       "25                  Sultanbeyli-MTHM                           stanbul   \n",
       "26                    erkezky-MTHM                           Tekirda   \n",
       "27                        Erdek-MTHM                          Balkesir   \n",
       "28                 Beyazt Cad.-MTHM                              Bursa   \n",
       "29                 Uluda niv.-MTHM                              Bursa   \n",
       "...                              ...                                ...   \n",
       "8216                        Calabozo                           Calabozo   \n",
       "8217                          V_VIEW  Miami-Fort Lauderdale-Miami Beach   \n",
       "8218                      White Pine                   Boise City-Nampa   \n",
       "8219                             nan  Miami-Fort Lauderdale-Miami Beach   \n",
       "8220             Portland - Spangler       Portland-Vancouver-Beaverton   \n",
       "8221              Talent - Rapp Lane                            Medford   \n",
       "8222                       Catao 40                             CATANO   \n",
       "8223            Hermiston - Municipa                Pendleton-Hermiston   \n",
       "8224                             nan  Miami-Fort Lauderdale-Miami Beach   \n",
       "8225                             nan  Miami-Fort Lauderdale-Miami Beach   \n",
       "8226            Saginaw - Delight Va                 Eugene-Springfield   \n",
       "8227                         Inpesca                            Inpesca   \n",
       "8228                       Flin Flon                           MANITOBA   \n",
       "8229                         Brandon                           MANITOBA   \n",
       "8230                 Winnipeg_Ellens                           MANITOBA   \n",
       "8231                 Winnipeg_Scotia                           MANITOBA   \n",
       "8232                             nan  Miami-Fort Lauderdale-Miami Beach   \n",
       "8233                             nan  Miami-Fort Lauderdale-Miami Beach   \n",
       "8234                             nan  Miami-Fort Lauderdale-Miami Beach   \n",
       "8235                             nan  Miami-Fort Lauderdale-Miami Beach   \n",
       "8236                             nan  Miami-Fort Lauderdale-Miami Beach   \n",
       "8237                   POMPANO_BEACH  Miami-Fort Lauderdale-Miami Beach   \n",
       "8238                     DANIA_BEACH  Miami-Fort Lauderdale-Miami Beach   \n",
       "8239                             nan  Miami-Fort Lauderdale-Miami Beach   \n",
       "8240                             nan  Miami-Fort Lauderdale-Miami Beach   \n",
       "8241              San Juan de Aragn                   DISTRITO FEDERAL   \n",
       "8242                             nan  Miami-Fort Lauderdale-Miami Beach   \n",
       "8243                             nan  Miami-Fort Lauderdale-Miami Beach   \n",
       "8244                             nan  Miami-Fort Lauderdale-Miami Beach   \n",
       "8245                       La Serena                          La Serena   \n",
       "\n",
       "     country   latitude   longitude  \n",
       "0         CL -22.085519  -70.188683  \n",
       "1         CL -22.342264  -68.650897  \n",
       "2         CL -32.776573  -70.938144  \n",
       "3         CL -36.735998  -73.118693  \n",
       "4         CL -32.797715  -70.898037  \n",
       "5         CL -37.031702  -73.138689  \n",
       "6         CL -32.779208  -70.959114  \n",
       "7         CL -36.996431  -73.115805  \n",
       "8         CL -32.823956  -71.006441  \n",
       "9         SE  59.325519   18.003961  \n",
       "10        SE  59.325519   18.003961  \n",
       "11        SE  59.443539   17.922361  \n",
       "12        SE  59.237058   17.838332  \n",
       "13        SE  59.345161   18.054282  \n",
       "14        CL -22.462145  -68.928062  \n",
       "15        SE  60.671552   17.146915  \n",
       "16        SE  59.317132   18.048787  \n",
       "17        SE  59.314624   18.075856  \n",
       "18        SE  59.336356   18.070626  \n",
       "19        SE  59.198124   17.621087  \n",
       "20        SE  59.859530   17.642484  \n",
       "21        CL -22.460271  -68.937707  \n",
       "22        CL -22.442839  -68.932546  \n",
       "23        TR  40.529350   28.784590  \n",
       "24        TR  40.195720   29.045880  \n",
       "25        TR  40.984470   29.268810  \n",
       "26        TR  41.318350   27.980180  \n",
       "27        TR  40.489720   27.978610  \n",
       "28        TR  40.185650   29.080490  \n",
       "29        TR  40.223370   28.871540  \n",
       "...      ...        ...         ...  \n",
       "8216      CL -36.996431  -73.115805  \n",
       "8217      US  26.073200  -80.338600  \n",
       "8218      US  43.577603 -116.178156  \n",
       "8219      US  26.593808  -80.058917  \n",
       "8220      US  45.259280 -122.588151  \n",
       "8221      US  42.229891 -122.787700  \n",
       "8222      US  18.428388  -66.141657  \n",
       "8223      US  45.828968 -119.262991  \n",
       "8224      US  26.593808  -80.058917  \n",
       "8225      US  26.593808  -80.058917  \n",
       "8226      US  43.834470 -123.035375  \n",
       "8227      CL -36.737202  -73.104427  \n",
       "8228      CA  54.765000 -101.875300  \n",
       "8229      CA  49.842200  -99.918900  \n",
       "8230      CA  49.948900  -97.396400  \n",
       "8231      CA  49.931900  -96.863100  \n",
       "8232      US  26.593808  -80.058917  \n",
       "8233      US  26.593808  -80.058917  \n",
       "8234      US  26.593808  -80.058917  \n",
       "8235      US  26.593808  -80.058917  \n",
       "8236      US  26.593808  -80.058917  \n",
       "8237      US  26.290600  -80.096900  \n",
       "8238      US  26.086400  -80.111400  \n",
       "8239      US  26.593808  -80.058917  \n",
       "8240      US  26.593808  -80.058917  \n",
       "8241      MX  19.452500  -99.086000  \n",
       "8242      US  26.593808  -80.058917  \n",
       "8243      US  26.593808  -80.058917  \n",
       "8244      US  26.593808  -80.058917  \n",
       "8245      CL -29.933007  -71.261966  \n",
       "\n",
       "[8246 rows x 5 columns]"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_open_aq_locations = \"open_aq_locations\"\n",
    "\n",
    "select_all_sql = \"\"\"\n",
    "SELECT * FROM {table_name}\n",
    "\"\"\".format(table_name=all_open_aq_locations)\n",
    "\n",
    "res = sql_api(carto_url, select_all_sql, carto_api_token)\n",
    "\n",
    "all_open_aq_locations = pd.DataFrame(res.json()[\"rows\"])\n",
    "\n",
    "column_order = [\"location\", \"city\", \"country\", \"latitude\", \"longitude\"]\n",
    "\n",
    "print(\"\\nA list of all locations ever reporting to the OpenAQ network:\")\n",
    "all_open_aq_locations[column_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sql_api(url, sql, key):\n",
    "    \"\"\" Execute sql request over API \"\"\"\n",
    "    \n",
    "    params = {\n",
    "        'api_key' : key,\n",
    "        'q'       : sql\n",
    "    }\n",
    "    r = req.get(url, params=params)\n",
    "    return(r)\n",
    "\n",
    "# CONSIDER: Is it good to consider all cols of type \"varchar\" as cols_with_apostrophes?\n",
    "def dump_row_contents(row, cols_and_types, cols_with_apostrophes=None):\n",
    "#def dump_row_contents(row, cols_and_types):\n",
    "    \"\"\" Format data from a dataframe for insert statements into a Carto table \"\"\"\n",
    "    dump = \"(\"\n",
    "    for ix in row.index:\n",
    "#         if ix in cols_with_apostrophes:\n",
    "#             # Replace with UTF8 code for an apostrophe\n",
    "#             # https://stackoverflow.com/questions/419718/html-code-for-an-apostrophe\n",
    "#             dump += \"'\" + str(row[ix]).replace(\"'\",\"&#8217\") + \"',\"\n",
    "        if cols_and_types[ix] in [\"date\", \"varchar\"]:\n",
    "            dump += \"'\" + str(row[ix]) + \"',\"\n",
    "        else:\n",
    "            dump += str(row[ix]) + \",\"\n",
    "    dump = dump[:-1]+\")\"\n",
    "    return(dump)\n",
    "\n",
    "def update_in_batches(data_df, batch_size, target_table_name, cols_and_types, cols_with_apostrophes=None):\n",
    "#def update_in_batches(data_df, batch_size, target_table_name, cols_and_types):\n",
    "    \"\"\" \n",
    "    Send new rows for Carto in smaller batch sizes.\n",
    "    A batch_size of 20 seems to work for the location data. \n",
    "    \"\"\"\n",
    "    \n",
    "    columns = str(tuple(data_df.columns)).replace(\"'\",\"\")\n",
    "    \n",
    "    num_batches = int(data_df.shape[0] / batch_size)\n",
    "\n",
    "    for batch in range(num_batches+1):\n",
    "        # Select sub-dataframe\n",
    "        sub_df = data_df.iloc[batch*batch_size:batch*batch_size+batch_size]\n",
    "        \n",
    "        # Remove apostrophes\n",
    "        #print(sub_df)\n",
    "        sub_df = toggle_apostrophes(sub_df, cols_with_apostrophes)\n",
    "        \n",
    "        # Create Insert SQL statement\n",
    "        values = \", \".join(list(sub_df.apply(lambda row: dump_row_contents(row, cols_and_types, cols_with_apostrophes), axis=1)))\n",
    "        #values = \", \".join(list(sub_df.apply(lambda row: dump_row_contents(row, cols_and_types), axis=1)))\n",
    "        insert_value_sql = \"\"\"\n",
    "        INSERT INTO {table_name} {columns} VALUES {values}\n",
    "        \"\"\".format(table_name=table_name, columns=columns, values=values)\n",
    "\n",
    "        res = sql_api(carto_url, insert_value_sql, carto_api_token)\n",
    "\n",
    "        if \"error\" in res.text:\n",
    "            print(res.text)\n",
    "            print(sub_df)\n",
    "            break\n",
    "\n",
    "        print(\"Completed up until index:\", batch*batch_size+batch_size)\n",
    "        \n",
    "def keep_geolocated(df):\n",
    "    keep_geotagged = pd.notnull(df[\"latitude\"]) & pd.notnull(df[\"longitude\"]) \n",
    "    df = df.loc[keep_geotagged]\n",
    "    return(df)\n",
    "\n",
    "def fix_precision_of_floats(df, float_columns, precision):\n",
    "    df = df.copy()\n",
    "    for col in float_columns:\n",
    "        df[col] = np.around(df[col],precision)\n",
    "    return(df)\n",
    "\n",
    "def toggle_apostrophes(df, cols_with_apostrophes, remove=True):\n",
    "    \"\"\"\n",
    "    Will switch between &#8217 and ' representation of an apostrophe\n",
    "    \"\"\"\n",
    "    if not cols_with_apostrophes:\n",
    "        cols_with_apostrophes = []\n",
    "    \n",
    "    df = df.copy()\n",
    "    for col in cols_with_apostrophes:\n",
    "        if remove:\n",
    "            df[col] = df[col].apply(lambda row: str(row).replace(\"'\", \"&#8217\"))\n",
    "        else:\n",
    "            df[col] = df[col].apply(lambda row: str(row).replace(\"&#8217\", \"'\"))\n",
    "    return(df)\n",
    "\n",
    "def update_table_without_duplicates(data_df, target_table_name, cols_and_types, float_cols=[\"latitude\", \"longitude\"], precision=8, cols_with_apostrophes=None):\n",
    "    \"\"\" \n",
    "    Determines whether there are new locations to add to the table.\n",
    "    Sends an SQL statement and returns the result of that operation to stdout.\n",
    "    \"\"\"\n",
    "    # column names to include\n",
    "    column_names = list(cols_and_types.keys())\n",
    "    \n",
    "    # Read in existing table\n",
    "    select_all_sql = \"\"\"\n",
    "    SELECT * FROM {table_name}\n",
    "    \"\"\".format(table_name=target_table_name)\n",
    "    res = sql_api(carto_url, select_all_sql, carto_api_token)\n",
    "    target_table = pd.DataFrame(res.json()[\"rows\"], columns=column_names)\n",
    "    \n",
    "    # Fix precision on float columns\n",
    "    target_table = fix_precision_of_floats(target_table, float_cols, 8)\n",
    "    \n",
    "    # Fix apostrophe change\n",
    "    target_table = toggle_apostrophes(target_table, cols_with_apostrophes, remove=False)\n",
    "    \n",
    "    # Determine unique observations in data_df (de-dupe in the new observations)\n",
    "    # http://pandas.pydata.org/pandas-docs/version/0.17/generated/pandas.DataFrame.drop_duplicates.html\n",
    "    obs = data_df[column_names] #.set_index(index_cols)\n",
    "    obs = obs.drop_duplicates(keep=\"first\")\n",
    "    obs = keep_geolocated(obs)\n",
    "    obs = fix_precision_of_floats(obs, float_cols, 8)\n",
    "    \n",
    "    # De-dupe between existing table and new observations\n",
    "    # https://stackoverflow.com/questions/29464234/compare-python-pandas-dataframes-for-matching-rows\n",
    "    \n",
    "    shared = pd.merge(target_table, obs, on=column_names, how=\"inner\")\n",
    "    #shared = pd.merge(target_table, obs, left_index=True, right_index=True, how=\"inner\")\n",
    "    \n",
    "    shared[\"key\"] = \"x\"\n",
    "    temp_df = pd.merge(obs, shared, on=column_names, how=\"left\")\n",
    "    #temp_df = pd.merge(obs, shared, left_index=True, right_index=True, how=\"left\")\n",
    "    \n",
    "    new_obs = temp_df[temp_df[\"key\"].isnull()].drop(\"key\", axis=1)\n",
    "    #new_obs = new_obs.reset_index()[column_names]\n",
    "    \n",
    "    print(\"Number of new observations added to\", target_table_name + \":\", new_obs.shape[0])\n",
    "    \n",
    "    # Add genuinely new observations to the existing table\n",
    "    update_in_batches(new_obs, 20, target_table_name, cols_and_types, cols_with_apostrophes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7271, 5)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = list(cols_and_types_locations.keys())\n",
    "target_table_name = \"open_aq_locations\"\n",
    "select_all_sql = \"\"\"\n",
    "SELECT * FROM {table_name}\n",
    "\"\"\".format(table_name=target_table_name)\n",
    "res = sql_api(carto_url, select_all_sql, carto_api_token)\n",
    "target_table = pd.DataFrame(res.json()[\"rows\"], columns=column_names)\n",
    "target_table = fix_precision_of_floats(target_table, [\"latitude\", \"longitude\"], 6)\n",
    "target_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7271, 5)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = dec8\n",
    "obs = data_df[column_names]\n",
    "obs = obs.drop_duplicates(keep=\"first\")\n",
    "obs = keep_geolocated(obs)\n",
    "obs = fix_precision_of_floats(obs, [\"latitude\", \"longitude\"], 6)\n",
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Escuela E-10</td>\n",
       "      <td>Tocopilla</td>\n",
       "      <td>CL</td>\n",
       "      <td>-22.085519</td>\n",
       "      <td>-70.188683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chiu Chiu</td>\n",
       "      <td>Calama</td>\n",
       "      <td>CL</td>\n",
       "      <td>-22.342264</td>\n",
       "      <td>-68.650897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Santa Margarita</td>\n",
       "      <td>Catemu</td>\n",
       "      <td>CL</td>\n",
       "      <td>-32.776573</td>\n",
       "      <td>-70.938144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Nueva Libertad</td>\n",
       "      <td>Talcahuano</td>\n",
       "      <td>CL</td>\n",
       "      <td>-36.735998</td>\n",
       "      <td>-73.118693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lo Campo</td>\n",
       "      <td>Panquehue</td>\n",
       "      <td>CL</td>\n",
       "      <td>-32.797715</td>\n",
       "      <td>-70.898037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Coronel Sur</td>\n",
       "      <td>Coronel</td>\n",
       "      <td>CL</td>\n",
       "      <td>-37.031702</td>\n",
       "      <td>-73.138689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Catemu</td>\n",
       "      <td>Catemu</td>\n",
       "      <td>CL</td>\n",
       "      <td>-32.779208</td>\n",
       "      <td>-70.959114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Calabozo</td>\n",
       "      <td>Coronel</td>\n",
       "      <td>CL</td>\n",
       "      <td>-36.996431</td>\n",
       "      <td>-73.115805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Romeral</td>\n",
       "      <td>Hijuelas</td>\n",
       "      <td>CL</td>\n",
       "      <td>-32.823956</td>\n",
       "      <td>-71.006441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lilla Essingen (E4/E20)</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>59.325519</td>\n",
       "      <td>18.003961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   location        city country   latitude  longitude\n",
       "0              Escuela E-10   Tocopilla      CL -22.085519 -70.188683\n",
       "7                 Chiu Chiu      Calama      CL -22.342264 -68.650897\n",
       "8           Santa Margarita      Catemu      CL -32.776573 -70.938144\n",
       "9            Nueva Libertad  Talcahuano      CL -36.735998 -73.118693\n",
       "10                 Lo Campo   Panquehue      CL -32.797715 -70.898037\n",
       "11              Coronel Sur     Coronel      CL -37.031702 -73.138689\n",
       "12                   Catemu      Catemu      CL -32.779208 -70.959114\n",
       "13                 Calabozo     Coronel      CL -36.996431 -73.115805\n",
       "14                  Romeral    Hijuelas      CL -32.823956 -71.006441\n",
       "15  Lilla Essingen (E4/E20)   Stockholm      SE  59.325519  18.003961"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location     Escuela E-10\n",
       "city            Tocopilla\n",
       "country                CL\n",
       "latitude         -22.0855\n",
       "longitude        -70.1887\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_table.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location     Escuela E-10\n",
       "city            Tocopilla\n",
       "country                CL\n",
       "latitude         -22.0855\n",
       "longitude        -70.1887\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_table.loc[0].equals(obs.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7250, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Escuela E-10</td>\n",
       "      <td>Tocopilla</td>\n",
       "      <td>CL</td>\n",
       "      <td>-22.085519</td>\n",
       "      <td>-70.188683</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chiu Chiu</td>\n",
       "      <td>Calama</td>\n",
       "      <td>CL</td>\n",
       "      <td>-22.342264</td>\n",
       "      <td>-68.650897</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Santa Margarita</td>\n",
       "      <td>Catemu</td>\n",
       "      <td>CL</td>\n",
       "      <td>-32.776573</td>\n",
       "      <td>-70.938144</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nueva Libertad</td>\n",
       "      <td>Talcahuano</td>\n",
       "      <td>CL</td>\n",
       "      <td>-36.735998</td>\n",
       "      <td>-73.118693</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lo Campo</td>\n",
       "      <td>Panquehue</td>\n",
       "      <td>CL</td>\n",
       "      <td>-32.797715</td>\n",
       "      <td>-70.898037</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Coronel Sur</td>\n",
       "      <td>Coronel</td>\n",
       "      <td>CL</td>\n",
       "      <td>-37.031702</td>\n",
       "      <td>-73.138689</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Catemu</td>\n",
       "      <td>Catemu</td>\n",
       "      <td>CL</td>\n",
       "      <td>-32.779208</td>\n",
       "      <td>-70.959114</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Calabozo</td>\n",
       "      <td>Coronel</td>\n",
       "      <td>CL</td>\n",
       "      <td>-36.996431</td>\n",
       "      <td>-73.115805</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Romeral</td>\n",
       "      <td>Hijuelas</td>\n",
       "      <td>CL</td>\n",
       "      <td>-32.823956</td>\n",
       "      <td>-71.006441</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lilla Essingen (E4/E20)</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>SE</td>\n",
       "      <td>59.325519</td>\n",
       "      <td>18.003961</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  location        city country   latitude  longitude key\n",
       "0             Escuela E-10   Tocopilla      CL -22.085519 -70.188683   x\n",
       "1                Chiu Chiu      Calama      CL -22.342264 -68.650897   x\n",
       "2          Santa Margarita      Catemu      CL -32.776573 -70.938144   x\n",
       "3           Nueva Libertad  Talcahuano      CL -36.735998 -73.118693   x\n",
       "4                 Lo Campo   Panquehue      CL -32.797715 -70.898037   x\n",
       "5              Coronel Sur     Coronel      CL -37.031702 -73.138689   x\n",
       "6                   Catemu      Catemu      CL -32.779208 -70.959114   x\n",
       "7                 Calabozo     Coronel      CL -36.996431 -73.115805   x\n",
       "8                  Romeral    Hijuelas      CL -32.823956 -71.006441   x\n",
       "9  Lilla Essingen (E4/E20)   Stockholm      SE  59.325519  18.003961   x"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared = target_table.merge(obs, on=column_names, how=\"inner\")\n",
    "shared[\"key\"] = \"x\"\n",
    "print(shared.shape)\n",
    "shared.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>MT00004</td>\n",
       "      <td>Zejtun (Citta' Beland)</td>\n",
       "      <td>MT</td>\n",
       "      <td>35.852291</td>\n",
       "      <td>14.538986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>Parque O'Higgins</td>\n",
       "      <td>Santiago</td>\n",
       "      <td>CL</td>\n",
       "      <td>-33.464142</td>\n",
       "      <td>-70.660797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>Bristol St Paul's</td>\n",
       "      <td>Bristol</td>\n",
       "      <td>GB</td>\n",
       "      <td>51.462839</td>\n",
       "      <td>-2.584482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>Belfast Stockman's Lane</td>\n",
       "      <td>Belfast</td>\n",
       "      <td>GB</td>\n",
       "      <td>54.572586</td>\n",
       "      <td>-5.974944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>Derby St Alkmund's Way</td>\n",
       "      <td>Derby</td>\n",
       "      <td>GB</td>\n",
       "      <td>52.922983</td>\n",
       "      <td>-1.469507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>Fisherman's Landing</td>\n",
       "      <td>Gladstone</td>\n",
       "      <td>AU</td>\n",
       "      <td>-23.793700</td>\n",
       "      <td>151.160100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>St. John's</td>\n",
       "      <td>NEWFOUNDLAND</td>\n",
       "      <td>CA</td>\n",
       "      <td>47.652800</td>\n",
       "      <td>-52.816700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>Lancaster</td>\n",
       "      <td>Coeur d'Alene</td>\n",
       "      <td>US</td>\n",
       "      <td>47.788900</td>\n",
       "      <td>-116.804400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>Children's Park Site</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>US</td>\n",
       "      <td>32.295300</td>\n",
       "      <td>-110.982200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2788</th>\n",
       "      <td>FR04158</td>\n",
       "      <td>Val-d'Oise</td>\n",
       "      <td>FR</td>\n",
       "      <td>49.063086</td>\n",
       "      <td>1.866381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>FR26002</td>\n",
       "      <td>Cte-d'Or</td>\n",
       "      <td>FR</td>\n",
       "      <td>47.304164</td>\n",
       "      <td>5.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2826</th>\n",
       "      <td>FR04023</td>\n",
       "      <td>Val-d'Oise</td>\n",
       "      <td>FR</td>\n",
       "      <td>49.046389</td>\n",
       "      <td>2.043056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2904</th>\n",
       "      <td>FR04051</td>\n",
       "      <td>Val-d'Oise</td>\n",
       "      <td>FR</td>\n",
       "      <td>48.951389</td>\n",
       "      <td>2.223611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3155</th>\n",
       "      <td>FR04024</td>\n",
       "      <td>Val-d'Oise</td>\n",
       "      <td>FR</td>\n",
       "      <td>48.990831</td>\n",
       "      <td>2.444722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164</th>\n",
       "      <td>FR26035</td>\n",
       "      <td>Cte-d'Or</td>\n",
       "      <td>FR</td>\n",
       "      <td>47.137225</td>\n",
       "      <td>4.950578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257</th>\n",
       "      <td>FR26014</td>\n",
       "      <td>Cte-d'Or</td>\n",
       "      <td>FR</td>\n",
       "      <td>47.340278</td>\n",
       "      <td>5.058333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3301</th>\n",
       "      <td>FR26010</td>\n",
       "      <td>Cte-d'Or</td>\n",
       "      <td>FR</td>\n",
       "      <td>47.345553</td>\n",
       "      <td>5.002222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3551</th>\n",
       "      <td>FR04048</td>\n",
       "      <td>Val-d'Oise</td>\n",
       "      <td>FR</td>\n",
       "      <td>49.100278</td>\n",
       "      <td>2.343889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3555</th>\n",
       "      <td>FR26043</td>\n",
       "      <td>Cte-d'Or</td>\n",
       "      <td>FR</td>\n",
       "      <td>47.315472</td>\n",
       "      <td>5.037429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3560</th>\n",
       "      <td>FR26005</td>\n",
       "      <td>Cte-d'Or</td>\n",
       "      <td>FR</td>\n",
       "      <td>47.308056</td>\n",
       "      <td>5.066111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599</th>\n",
       "      <td>FR19061</td>\n",
       "      <td>Ctes-d'Armor</td>\n",
       "      <td>FR</td>\n",
       "      <td>48.516669</td>\n",
       "      <td>-2.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     location                    city country   latitude  \\\n",
       "76                    MT00004  Zejtun (Citta' Beland)      MT  35.852291   \n",
       "549          Parque O'Higgins                Santiago      CL -33.464142   \n",
       "638         Bristol St Paul's                 Bristol      GB  51.462839   \n",
       "689   Belfast Stockman's Lane                 Belfast      GB  54.572586   \n",
       "700    Derby St Alkmund's Way                   Derby      GB  52.922983   \n",
       "1067      Fisherman's Landing               Gladstone      AU -23.793700   \n",
       "1238               St. John's            NEWFOUNDLAND      CA  47.652800   \n",
       "1381                Lancaster           Coeur d'Alene      US  47.788900   \n",
       "1561     Children's Park Site                  Tucson      US  32.295300   \n",
       "2788                  FR04158              Val-d'Oise      FR  49.063086   \n",
       "2798                  FR26002               Cte-d'Or      FR  47.304164   \n",
       "2826                  FR04023              Val-d'Oise      FR  49.046389   \n",
       "2904                  FR04051              Val-d'Oise      FR  48.951389   \n",
       "3155                  FR04024              Val-d'Oise      FR  48.990831   \n",
       "3164                  FR26035               Cte-d'Or      FR  47.137225   \n",
       "3257                  FR26014               Cte-d'Or      FR  47.340278   \n",
       "3301                  FR26010               Cte-d'Or      FR  47.345553   \n",
       "3551                  FR04048              Val-d'Oise      FR  49.100278   \n",
       "3555                  FR26043               Cte-d'Or      FR  47.315472   \n",
       "3560                  FR26005               Cte-d'Or      FR  47.308056   \n",
       "3599                  FR19061           Ctes-d'Armor      FR  48.516669   \n",
       "\n",
       "       longitude  \n",
       "76     14.538986  \n",
       "549   -70.660797  \n",
       "638    -2.584482  \n",
       "689    -5.974944  \n",
       "700    -1.469507  \n",
       "1067  151.160100  \n",
       "1238  -52.816700  \n",
       "1381 -116.804400  \n",
       "1561 -110.982200  \n",
       "2788    1.866381  \n",
       "2798    5.020000  \n",
       "2826    2.043056  \n",
       "2904    2.223611  \n",
       "3155    2.444722  \n",
       "3164    4.950578  \n",
       "3257    5.058333  \n",
       "3301    5.002222  \n",
       "3551    2.343889  \n",
       "3555    5.037429  \n",
       "3560    5.066111  \n",
       "3599   -2.750000  "
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = pd.merge(obs, shared, on=column_names, how=\"left\")\n",
    "new_obs = temp_df[temp_df[\"key\"].isnull()].drop(\"key\", axis=1)\n",
    "#new_obs = new_obs.reset_index()[column_names]\n",
    "new_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new observations added to open_aq_locations: 7271\n",
      "Completed up until index: 20\n",
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Completed up until index: 160\n",
      "Completed up until index: 180\n",
      "Completed up until index: 200\n",
      "Completed up until index: 220\n",
      "Completed up until index: 240\n",
      "Completed up until index: 260\n",
      "Completed up until index: 280\n",
      "Completed up until index: 300\n",
      "Completed up until index: 320\n",
      "Completed up until index: 340\n",
      "Completed up until index: 360\n",
      "Completed up until index: 380\n",
      "Completed up until index: 400\n",
      "Completed up until index: 420\n",
      "Completed up until index: 440\n",
      "Completed up until index: 460\n",
      "Completed up until index: 480\n",
      "Completed up until index: 500\n",
      "Completed up until index: 520\n",
      "Completed up until index: 540\n",
      "Completed up until index: 560\n",
      "Completed up until index: 580\n",
      "Completed up until index: 600\n",
      "Completed up until index: 620\n",
      "Completed up until index: 640\n",
      "Completed up until index: 660\n",
      "Completed up until index: 680\n",
      "Completed up until index: 700\n",
      "Completed up until index: 720\n",
      "Completed up until index: 740\n",
      "Completed up until index: 760\n",
      "Completed up until index: 780\n",
      "Completed up until index: 800\n",
      "Completed up until index: 820\n",
      "Completed up until index: 840\n",
      "Completed up until index: 860\n",
      "Completed up until index: 880\n",
      "Completed up until index: 900\n",
      "Completed up until index: 920\n",
      "Completed up until index: 940\n",
      "Completed up until index: 960\n",
      "Completed up until index: 980\n",
      "Completed up until index: 1000\n",
      "Completed up until index: 1020\n",
      "Completed up until index: 1040\n",
      "Completed up until index: 1060\n",
      "Completed up until index: 1080\n",
      "Completed up until index: 1100\n",
      "Completed up until index: 1120\n",
      "Completed up until index: 1140\n",
      "Completed up until index: 1160\n",
      "Completed up until index: 1180\n",
      "Completed up until index: 1200\n",
      "Completed up until index: 1220\n",
      "Completed up until index: 1240\n",
      "Completed up until index: 1260\n",
      "Completed up until index: 1280\n",
      "Completed up until index: 1300\n",
      "Completed up until index: 1320\n",
      "Completed up until index: 1340\n",
      "Completed up until index: 1360\n",
      "Completed up until index: 1380\n",
      "Completed up until index: 1400\n",
      "Completed up until index: 1420\n",
      "Completed up until index: 1440\n",
      "Completed up until index: 1460\n",
      "Completed up until index: 1480\n",
      "Completed up until index: 1500\n",
      "Completed up until index: 1520\n",
      "Completed up until index: 1540\n",
      "Completed up until index: 1560\n",
      "Completed up until index: 1580\n",
      "Completed up until index: 1600\n",
      "Completed up until index: 1620\n",
      "Completed up until index: 1640\n",
      "Completed up until index: 1660\n",
      "Completed up until index: 1680\n",
      "Completed up until index: 1700\n",
      "Completed up until index: 1720\n",
      "Completed up until index: 1740\n",
      "Completed up until index: 1760\n",
      "Completed up until index: 1780\n",
      "Completed up until index: 1800\n",
      "Completed up until index: 1820\n",
      "Completed up until index: 1840\n",
      "Completed up until index: 1860\n",
      "Completed up until index: 1880\n",
      "Completed up until index: 1900\n",
      "Completed up until index: 1920\n",
      "Completed up until index: 1940\n",
      "Completed up until index: 1960\n",
      "Completed up until index: 1980\n",
      "Completed up until index: 2000\n",
      "Completed up until index: 2020\n",
      "Completed up until index: 2040\n",
      "Completed up until index: 2060\n",
      "Completed up until index: 2080\n",
      "Completed up until index: 2100\n",
      "Completed up until index: 2120\n",
      "Completed up until index: 2140\n",
      "Completed up until index: 2160\n",
      "Completed up until index: 2180\n",
      "Completed up until index: 2200\n",
      "Completed up until index: 2220\n",
      "Completed up until index: 2240\n",
      "Completed up until index: 2260\n",
      "Completed up until index: 2280\n",
      "Completed up until index: 2300\n",
      "Completed up until index: 2320\n",
      "Completed up until index: 2340\n",
      "Completed up until index: 2360\n",
      "Completed up until index: 2380\n",
      "Completed up until index: 2400\n",
      "Completed up until index: 2420\n",
      "Completed up until index: 2440\n",
      "Completed up until index: 2460\n",
      "Completed up until index: 2480\n",
      "Completed up until index: 2500\n",
      "Completed up until index: 2520\n",
      "Completed up until index: 2540\n",
      "Completed up until index: 2560\n",
      "Completed up until index: 2580\n",
      "Completed up until index: 2600\n",
      "Completed up until index: 2620\n",
      "Completed up until index: 2640\n",
      "Completed up until index: 2660\n",
      "Completed up until index: 2680\n",
      "Completed up until index: 2700\n",
      "Completed up until index: 2720\n",
      "Completed up until index: 2740\n",
      "Completed up until index: 2760\n",
      "Completed up until index: 2780\n",
      "Completed up until index: 2800\n",
      "Completed up until index: 2820\n",
      "Completed up until index: 2840\n",
      "Completed up until index: 2860\n",
      "Completed up until index: 2880\n",
      "Completed up until index: 2900\n",
      "Completed up until index: 2920\n",
      "Completed up until index: 2940\n",
      "Completed up until index: 2960\n",
      "Completed up until index: 2980\n",
      "Completed up until index: 3000\n",
      "Completed up until index: 3020\n",
      "Completed up until index: 3040\n",
      "Completed up until index: 3060\n",
      "Completed up until index: 3080\n",
      "Completed up until index: 3100\n",
      "Completed up until index: 3120\n",
      "Completed up until index: 3140\n",
      "Completed up until index: 3160\n",
      "Completed up until index: 3180\n",
      "Completed up until index: 3200\n",
      "Completed up until index: 3220\n",
      "Completed up until index: 3240\n",
      "Completed up until index: 3260\n",
      "Completed up until index: 3280\n",
      "Completed up until index: 3300\n",
      "Completed up until index: 3320\n",
      "Completed up until index: 3340\n",
      "Completed up until index: 3360\n",
      "Completed up until index: 3380\n",
      "Completed up until index: 3400\n",
      "Completed up until index: 3420\n",
      "Completed up until index: 3440\n",
      "Completed up until index: 3460\n",
      "Completed up until index: 3480\n",
      "Completed up until index: 3500\n",
      "Completed up until index: 3520\n",
      "Completed up until index: 3540\n",
      "Completed up until index: 3560\n",
      "Completed up until index: 3580\n",
      "Completed up until index: 3600\n",
      "Completed up until index: 3620\n",
      "Completed up until index: 3640\n",
      "Completed up until index: 3660\n",
      "Completed up until index: 3680\n",
      "Completed up until index: 3700\n",
      "Completed up until index: 3720\n",
      "Completed up until index: 3740\n",
      "Completed up until index: 3760\n",
      "Completed up until index: 3780\n",
      "Completed up until index: 3800\n",
      "Completed up until index: 3820\n",
      "Completed up until index: 3840\n",
      "Completed up until index: 3860\n",
      "Completed up until index: 3880\n",
      "Completed up until index: 3900\n",
      "Completed up until index: 3920\n",
      "Completed up until index: 3940\n",
      "Completed up until index: 3960\n",
      "Completed up until index: 3980\n",
      "Completed up until index: 4000\n",
      "Completed up until index: 4020\n",
      "Completed up until index: 4040\n",
      "Completed up until index: 4060\n",
      "Completed up until index: 4080\n",
      "Completed up until index: 4100\n",
      "Completed up until index: 4120\n",
      "Completed up until index: 4140\n",
      "Completed up until index: 4160\n",
      "Completed up until index: 4180\n",
      "Completed up until index: 4200\n",
      "Completed up until index: 4220\n",
      "Completed up until index: 4240\n",
      "Completed up until index: 4260\n",
      "Completed up until index: 4280\n",
      "Completed up until index: 4300\n",
      "Completed up until index: 4320\n",
      "Completed up until index: 4340\n",
      "Completed up until index: 4360\n",
      "Completed up until index: 4380\n",
      "Completed up until index: 4400\n",
      "Completed up until index: 4420\n",
      "Completed up until index: 4440\n",
      "Completed up until index: 4460\n",
      "Completed up until index: 4480\n",
      "Completed up until index: 4500\n",
      "Completed up until index: 4520\n",
      "Completed up until index: 4540\n",
      "Completed up until index: 4560\n",
      "Completed up until index: 4580\n",
      "Completed up until index: 4600\n",
      "Completed up until index: 4620\n",
      "Completed up until index: 4640\n",
      "Completed up until index: 4660\n",
      "Completed up until index: 4680\n",
      "Completed up until index: 4700\n",
      "Completed up until index: 4720\n",
      "Completed up until index: 4740\n",
      "Completed up until index: 4760\n",
      "Completed up until index: 4780\n",
      "Completed up until index: 4800\n",
      "Completed up until index: 4820\n",
      "Completed up until index: 4840\n",
      "Completed up until index: 4860\n",
      "Completed up until index: 4880\n",
      "Completed up until index: 4900\n",
      "Completed up until index: 4920\n",
      "Completed up until index: 4940\n",
      "Completed up until index: 4960\n",
      "Completed up until index: 4980\n",
      "Completed up until index: 5000\n",
      "Completed up until index: 5020\n",
      "Completed up until index: 5040\n",
      "Completed up until index: 5060\n",
      "Completed up until index: 5080\n",
      "Completed up until index: 5100\n",
      "Completed up until index: 5120\n",
      "Completed up until index: 5140\n",
      "Completed up until index: 5160\n",
      "Completed up until index: 5180\n",
      "Completed up until index: 5200\n",
      "Completed up until index: 5220\n",
      "Completed up until index: 5240\n",
      "Completed up until index: 5260\n",
      "Completed up until index: 5280\n",
      "Completed up until index: 5300\n",
      "Completed up until index: 5320\n",
      "Completed up until index: 5340\n",
      "Completed up until index: 5360\n",
      "Completed up until index: 5380\n",
      "Completed up until index: 5400\n",
      "Completed up until index: 5420\n",
      "Completed up until index: 5440\n",
      "Completed up until index: 5460\n",
      "Completed up until index: 5480\n",
      "Completed up until index: 5500\n",
      "Completed up until index: 5520\n",
      "Completed up until index: 5540\n",
      "Completed up until index: 5560\n",
      "Completed up until index: 5580\n",
      "Completed up until index: 5600\n",
      "Completed up until index: 5620\n",
      "Completed up until index: 5640\n",
      "Completed up until index: 5660\n",
      "Completed up until index: 5680\n",
      "Completed up until index: 5700\n",
      "Completed up until index: 5720\n",
      "Completed up until index: 5740\n",
      "Completed up until index: 5760\n",
      "Completed up until index: 5780\n",
      "Completed up until index: 5800\n",
      "Completed up until index: 5820\n",
      "Completed up until index: 5840\n",
      "Completed up until index: 5860\n",
      "Completed up until index: 5880\n",
      "Completed up until index: 5900\n",
      "Completed up until index: 5920\n",
      "Completed up until index: 5940\n",
      "Completed up until index: 5960\n",
      "Completed up until index: 5980\n",
      "Completed up until index: 6000\n",
      "Completed up until index: 6020\n",
      "Completed up until index: 6040\n",
      "Completed up until index: 6060\n",
      "Completed up until index: 6080\n",
      "Completed up until index: 6100\n",
      "Completed up until index: 6120\n",
      "Completed up until index: 6140\n",
      "Completed up until index: 6160\n",
      "Completed up until index: 6180\n",
      "Completed up until index: 6200\n",
      "Completed up until index: 6220\n",
      "Completed up until index: 6240\n",
      "Completed up until index: 6260\n",
      "Completed up until index: 6280\n",
      "Completed up until index: 6300\n",
      "Completed up until index: 6320\n",
      "Completed up until index: 6340\n",
      "Completed up until index: 6360\n",
      "Completed up until index: 6380\n",
      "Completed up until index: 6400\n",
      "Completed up until index: 6420\n",
      "Completed up until index: 6440\n",
      "Completed up until index: 6460\n",
      "Completed up until index: 6480\n",
      "Completed up until index: 6500\n",
      "Completed up until index: 6520\n",
      "Completed up until index: 6540\n",
      "Completed up until index: 6560\n",
      "Completed up until index: 6580\n",
      "Completed up until index: 6600\n",
      "Completed up until index: 6620\n",
      "Completed up until index: 6640\n",
      "Completed up until index: 6660\n",
      "Completed up until index: 6680\n",
      "Completed up until index: 6700\n",
      "Completed up until index: 6720\n",
      "Completed up until index: 6740\n",
      "Completed up until index: 6760\n",
      "Completed up until index: 6780\n",
      "Completed up until index: 6800\n",
      "Completed up until index: 6820\n",
      "Completed up until index: 6840\n",
      "Completed up until index: 6860\n",
      "Completed up until index: 6880\n",
      "Completed up until index: 6900\n",
      "Completed up until index: 6920\n",
      "Completed up until index: 6940\n",
      "Completed up until index: 6960\n",
      "Completed up until index: 6980\n",
      "Completed up until index: 7000\n",
      "Completed up until index: 7020\n",
      "Completed up until index: 7040\n",
      "Completed up until index: 7060\n",
      "Completed up until index: 7080\n",
      "Completed up until index: 7100\n",
      "Completed up until index: 7120\n",
      "Completed up until index: 7140\n",
      "Completed up until index: 7160\n",
      "Completed up until index: 7180\n",
      "Completed up until index: 7200\n",
      "Completed up until index: 7220\n",
      "Completed up until index: 7240\n",
      "Completed up until index: 7260\n",
      "Completed up until index: 7280\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of new observations added to\", target_table_name + \":\", new_obs.shape[0])\n",
    "cols_and_types =cols_and_types_locations\n",
    "cols_with_apostrophes = [\"location\", \"city\",\"country\"]\n",
    "update_in_batches(new_obs, 20, target_table_name, cols_and_types, cols_with_apostrophes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Miscellaneous helper tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Table for converting from two letter ISO to three letter ISO\n",
    "isos = pd.read_csv(\"/Users/nathansuberi/Desktop/Code Portfolio/ResourceWatchCode/Conversion_Standards/iso_conversions.csv\", sep=\"\\t\", header=None)\n",
    "isos.columns = [\"country\", \"iso2\", \"iso3\", \"num\"]\n",
    "iso2s = isos.set_index(\"iso2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interacting with Carto Tables\n",
    "* Table creation (locations, history)\n",
    "* Table destruction (locations, history... in case need to start over due to dev mistakes)\n",
    "* Adding new rows to history (after querying an API to get new data)\n",
    "* Adding new locations (if newly observed data fall in previously unlisted sensor locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete table with history of OpenAQ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"rows\":[],\"time\":0.01,\"fields\":{},\"total_rows\":0}\n"
     ]
    }
   ],
   "source": [
    "# ### CAREFUL ###\n",
    "# # Leave commented out majority of time, unless sure you want to delete history\n",
    "\n",
    "# # Delete table sql\n",
    "# # Select all from a table\n",
    "# table_name = \"open_aq_history\"\n",
    "\n",
    "# delete_table_sql = \"\"\"\n",
    "# DROP TABLE {table_name}\n",
    "# \"\"\".format(table_name=table_name)\n",
    "\n",
    "# res = sql_api(carto_url, delete_table_sql, carto_api_token)\n",
    "# print(res.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create table to store history of OpenAQ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"error\":[\"relation \\\"open_aq_history\\\" already exists\"]}\n"
     ]
    }
   ],
   "source": [
    "# Define the column names and types\n",
    "cols_and_types_history = {\n",
    "    #col name: Carto col type\n",
    "    \"lastUpdated\":\"date\",\n",
    "    \"value\":\"float\",\n",
    "    \"parameter\":\"varchar\",\n",
    "    \"sourceName\":\"varchar\",\n",
    "    \"location\":\"varchar\",\n",
    "    \"city\":\"varchar\",\n",
    "    \"unit\":\"varchar\",\n",
    "    \"latitude\":\"float\",\n",
    "    \"longitude\":\"float\"\n",
    "}\n",
    "\n",
    "# Create table sql\n",
    "table_name = \"open_aq_history\"\n",
    "\n",
    "columns_and_data_types_history = \", \".join([col + \" \" + cols_and_types_history[col] for col in cols_and_types_history])\n",
    "\n",
    "create_table_sql = \"\"\"\n",
    "CREATE TABLE {table_name}\n",
    " (\n",
    " {columns_and_data_types}\n",
    " );\n",
    "\"\"\".format(table_name=table_name, columns_and_data_types=columns_and_data_types_history)\n",
    "\n",
    "res = sql_api(carto_url, create_table_sql, carto_api_token)\n",
    "print(res.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete table with previously observed locations of OpenAQ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"rows\":[],\"time\":0.011,\"fields\":{},\"total_rows\":0}\n"
     ]
    }
   ],
   "source": [
    "### CAREFUL ###\n",
    "# Leave commented out majority of time, unless sure you want to delete table of observed locations\n",
    "\n",
    "table_name = \"open_aq_locations\"\n",
    "\n",
    "delete_table_sql = \"\"\"\n",
    "DROP TABLE {table_name}\n",
    "\"\"\".format(table_name=table_name)\n",
    "\n",
    "res = sql_api(carto_url, delete_table_sql, carto_api_token)\n",
    "print(res.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create table for observed locations in OpenAQ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"rows\":[],\"time\":0.008,\"fields\":{},\"total_rows\":0}\n"
     ]
    }
   ],
   "source": [
    "# Define the column names and types\n",
    "cols_and_types_locations = {\n",
    "    #col name: Carto col type\n",
    "    \"location\":\"varchar\",\n",
    "    \"city\":\"varchar\",\n",
    "    \"country\":\"varchar\",\n",
    "    \"latitude\":\"float\",\n",
    "    \"longitude\":\"float\"\n",
    "}\n",
    "\n",
    "# Create table sql\n",
    "table_name = \"open_aq_locations\"\n",
    "\n",
    "columns_and_data_types_locations = \", \".join([col + \" \" + cols_and_types_locations[col] for col in cols_and_types_locations])\n",
    "\n",
    "create_table_sql = \"\"\"\n",
    "CREATE TABLE {table_name}\n",
    " (\n",
    " {columns_and_data_types}\n",
    " );\n",
    "\"\"\".format(table_name=table_name, columns_and_data_types=columns_and_data_types_locations)\n",
    "\n",
    "res = sql_api(carto_url, create_table_sql, carto_api_token)\n",
    "print(res.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check OpenAQ API 'locations' endpoint for acknowledged sensor locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city            False\n",
      "latitude         True\n",
      "longitude        True\n",
      "iso3             True\n",
      "firstUpdated    False\n",
      "location        False\n",
      "sourceName      False\n",
      "dtype: bool\n",
      "number with no latitude 180\n",
      "number with no longitude 180\n",
      "number with no iso3 1\n",
      "Number of rows in OpenAQ locations database removed due to not having geo-coordinates: 180\n"
     ]
    }
   ],
   "source": [
    "# url = \"https://api.openaq.org/v1/locations\"\n",
    "\n",
    "# # There are a total of 8055 locations in the database so far, according to this query\n",
    "# # so this shouldn't miss any... but it may at some point\n",
    "\n",
    "# ### FRANCIS ###\n",
    "# # The 10000 limit on requests is a hard limit in their API... what to do if there are more than \n",
    "# # 10000 observations in the desired endpoint?\n",
    "# params = {\n",
    "#     \"limit\":10000\n",
    "# }\n",
    "\n",
    "# res = req.get(url, params=params)\n",
    "# data = res.json()[\"results\"]\n",
    "# locations = pd.io.json.json_normalize(data, errors='ignore')\n",
    "# locations.columns = [\"city\", \"latitude\", \"longitude\", \"count\", \"country\", \"firstUpdated\", \"lastUpdated\",\n",
    "#              \"location\", \"parameters\", \"sourceName\", \"sourceNames\"]\n",
    "# locations[\"iso3\"] = iso2s.loc[locations[\"country\"], \"iso3\"].values\n",
    "# # Note - not storing parameters because these could change over time and it would be a pain to update\n",
    "# locations = locations[[\"city\", \"latitude\", \"longitude\", \"iso3\", \"firstUpdated\", \"location\", \"sourceName\"]]\n",
    "\n",
    "# pre_clean = locations.shape[0]\n",
    "\n",
    "# # View columns that have null values\n",
    "# # https://stackoverflow.com/questions/14016247/python-find-integer-index-of-rows-with-nan-in-pandas\n",
    "# print(pd.isnull(locations).any())\n",
    "# print(\"number with no latitude\",sum(pd.isnull(locations[\"latitude\"])))\n",
    "# print(\"number with no longitude\",sum(pd.isnull(locations[\"longitude\"])))\n",
    "# print(\"number with no iso3\",sum(pd.isnull(locations[\"iso3\"])))\n",
    "\n",
    "# keep_geotagged = pd.notnull(locations[\"latitude\"]) & pd.notnull(locations[\"longitude\"]) \n",
    "\n",
    "# # Remove all points that don't have a lat-lon\n",
    "# locations = locations.loc[keep_geotagged]\n",
    "\n",
    "# # Convert any remaining nan into empty string\n",
    "# # http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.DataFrame.fillna.html\n",
    "# locations = locations.fillna(value=\"\")\n",
    "\n",
    "# post_clean = locations.shape[0]\n",
    "# print(\"Number of rows in OpenAQ locations database removed due to not having geo-coordinates:\", pre_clean - post_clean)\n",
    "\n",
    "# ## Having issues with non-standard characters... how to deal with this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>iso3</th>\n",
       "      <th>firstUpdated</th>\n",
       "      <th>location</th>\n",
       "      <th>sourceName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>47.932907</td>\n",
       "      <td>106.921390</td>\n",
       "      <td>MNG</td>\n",
       "      <td>2015-09-01T00:00:00.000Z</td>\n",
       "      <td>100 ail</td>\n",
       "      <td>Agaar.mn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Omaha-Council Bluffs</td>\n",
       "      <td>41.322470</td>\n",
       "      <td>-95.937990</td>\n",
       "      <td>USA</td>\n",
       "      <td>2016-03-06T19:00:00.000Z</td>\n",
       "      <td>16th and Whitmore</td>\n",
       "      <td>AirNow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Farmington</td>\n",
       "      <td>36.809700</td>\n",
       "      <td>-107.651700</td>\n",
       "      <td>USA</td>\n",
       "      <td>2016-03-06T19:00:00.000Z</td>\n",
       "      <td>1NL Navajo Lake</td>\n",
       "      <td>AirNow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21 de mayo</td>\n",
       "      <td>-37.471184</td>\n",
       "      <td>-72.361465</td>\n",
       "      <td>CHL</td>\n",
       "      <td>2015-09-23T14:00:00.000Z</td>\n",
       "      <td>21 de mayo</td>\n",
       "      <td>Chile - SINCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tucson</td>\n",
       "      <td>32.205000</td>\n",
       "      <td>-110.877200</td>\n",
       "      <td>USA</td>\n",
       "      <td>2016-03-06T19:00:00.000Z</td>\n",
       "      <td>22nd Street &amp; Craycr</td>\n",
       "      <td>AirNow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   city   latitude   longitude iso3              firstUpdated  \\\n",
       "0           Ulaanbaatar  47.932907  106.921390  MNG  2015-09-01T00:00:00.000Z   \n",
       "1  Omaha-Council Bluffs  41.322470  -95.937990  USA  2016-03-06T19:00:00.000Z   \n",
       "2            Farmington  36.809700 -107.651700  USA  2016-03-06T19:00:00.000Z   \n",
       "3            21 de mayo -37.471184  -72.361465  CHL  2015-09-23T14:00:00.000Z   \n",
       "4                Tucson  32.205000 -110.877200  USA  2016-03-06T19:00:00.000Z   \n",
       "\n",
       "               location     sourceName  \n",
       "0               100 ail       Agaar.mn  \n",
       "1     16th and Whitmore         AirNow  \n",
       "2       1NL Navajo Lake         AirNow  \n",
       "3            21 de mayo  Chile - SINCA  \n",
       "4  22nd Street & Craycr         AirNow  "
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Use coordinates instead of location\n",
    "# # OR use location, city, country\n",
    "# # Check documentation for unique id\n",
    "\n",
    "# locations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert these observed sensor locations into open_aq_locations Carto table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed up until index: 40\n",
      "Completed up until index: 60\n",
      "Completed up until index: 80\n",
      "Completed up until index: 100\n",
      "Completed up until index: 120\n",
      "Completed up until index: 140\n",
      "Completed up until index: 160\n",
      "Completed up until index: 180\n",
      "Completed up until index: 200\n",
      "Completed up until index: 220\n",
      "Completed up until index: 240\n",
      "Completed up until index: 260\n",
      "Completed up until index: 280\n",
      "Completed up until index: 300\n",
      "Completed up until index: 320\n",
      "Completed up until index: 340\n",
      "Completed up until index: 360\n",
      "Completed up until index: 380\n",
      "Completed up until index: 400\n",
      "Completed up until index: 420\n",
      "Completed up until index: 440\n",
      "Completed up until index: 460\n",
      "Completed up until index: 480\n",
      "Completed up until index: 500\n",
      "Completed up until index: 520\n",
      "Completed up until index: 540\n",
      "Completed up until index: 560\n",
      "Completed up until index: 580\n",
      "Completed up until index: 600\n",
      "Completed up until index: 620\n",
      "Completed up until index: 640\n",
      "Completed up until index: 660\n",
      "Completed up until index: 680\n",
      "Completed up until index: 700\n",
      "Completed up until index: 720\n",
      "Completed up until index: 740\n",
      "Completed up until index: 760\n",
      "Completed up until index: 780\n",
      "Completed up until index: 800\n",
      "Completed up until index: 820\n",
      "Completed up until index: 840\n",
      "Completed up until index: 860\n",
      "Completed up until index: 880\n",
      "Completed up until index: 900\n",
      "Completed up until index: 920\n",
      "Completed up until index: 940\n",
      "Completed up until index: 960\n",
      "Completed up until index: 980\n",
      "Completed up until index: 1000\n",
      "Completed up until index: 1020\n",
      "Completed up until index: 1040\n",
      "Completed up until index: 1060\n",
      "Completed up until index: 1080\n",
      "Completed up until index: 1100\n",
      "Completed up until index: 1120\n",
      "Completed up until index: 1140\n",
      "Completed up until index: 1160\n",
      "Completed up until index: 1180\n",
      "Completed up until index: 1200\n",
      "Completed up until index: 1220\n",
      "Completed up until index: 1240\n",
      "Completed up until index: 1260\n",
      "Completed up until index: 1280\n",
      "Completed up until index: 1300\n",
      "Completed up until index: 1320\n",
      "Completed up until index: 1340\n",
      "Completed up until index: 1360\n",
      "Completed up until index: 1380\n",
      "Completed up until index: 1400\n",
      "Completed up until index: 1420\n",
      "Completed up until index: 1440\n",
      "Completed up until index: 1460\n",
      "Completed up until index: 1480\n",
      "Completed up until index: 1500\n",
      "Completed up until index: 1520\n",
      "Completed up until index: 1540\n",
      "Completed up until index: 1560\n",
      "Completed up until index: 1580\n",
      "Completed up until index: 1600\n",
      "Completed up until index: 1620\n",
      "Completed up until index: 1640\n",
      "Completed up until index: 1660\n",
      "Completed up until index: 1680\n",
      "Completed up until index: 1700\n",
      "Completed up until index: 1720\n",
      "Completed up until index: 1740\n",
      "Completed up until index: 1760\n",
      "Completed up until index: 1780\n",
      "Completed up until index: 1800\n",
      "Completed up until index: 1820\n",
      "Completed up until index: 1840\n",
      "Completed up until index: 1860\n",
      "Completed up until index: 1880\n",
      "Completed up until index: 1900\n",
      "Completed up until index: 1920\n",
      "Completed up until index: 1940\n",
      "Completed up until index: 1960\n",
      "Completed up until index: 1980\n",
      "Completed up until index: 2000\n",
      "Completed up until index: 2020\n",
      "Completed up until index: 2040\n",
      "Completed up until index: 2060\n",
      "Completed up until index: 2080\n",
      "Completed up until index: 2100\n",
      "Completed up until index: 2120\n",
      "Completed up until index: 2140\n",
      "Completed up until index: 2160\n",
      "Completed up until index: 2180\n",
      "Completed up until index: 2200\n",
      "Completed up until index: 2220\n",
      "Completed up until index: 2240\n",
      "Completed up until index: 2260\n",
      "Completed up until index: 2280\n",
      "Completed up until index: 2300\n",
      "Completed up until index: 2320\n",
      "Completed up until index: 2340\n",
      "Completed up until index: 2360\n",
      "Completed up until index: 2380\n",
      "Completed up until index: 2400\n",
      "Completed up until index: 2420\n",
      "Completed up until index: 2440\n",
      "Completed up until index: 2460\n",
      "Completed up until index: 2480\n",
      "Completed up until index: 2500\n",
      "Completed up until index: 2520\n",
      "Completed up until index: 2540\n",
      "Completed up until index: 2560\n",
      "Completed up until index: 2580\n",
      "Completed up until index: 2600\n",
      "Completed up until index: 2620\n",
      "Completed up until index: 2640\n",
      "Completed up until index: 2660\n",
      "Completed up until index: 2680\n",
      "Completed up until index: 2700\n",
      "Completed up until index: 2720\n",
      "Completed up until index: 2740\n",
      "Completed up until index: 2760\n",
      "Completed up until index: 2780\n",
      "Completed up until index: 2800\n",
      "Completed up until index: 2820\n",
      "Completed up until index: 2840\n",
      "Completed up until index: 2860\n",
      "Completed up until index: 2880\n",
      "Completed up until index: 2900\n",
      "Completed up until index: 2920\n",
      "Completed up until index: 2940\n",
      "Completed up until index: 2960\n",
      "Completed up until index: 2980\n",
      "Completed up until index: 3000\n",
      "Completed up until index: 3020\n",
      "Completed up until index: 3040\n",
      "Completed up until index: 3060\n",
      "Completed up until index: 3080\n",
      "Completed up until index: 3100\n",
      "Completed up until index: 3120\n",
      "Completed up until index: 3140\n",
      "Completed up until index: 3160\n",
      "Completed up until index: 3180\n",
      "Completed up until index: 3200\n",
      "Completed up until index: 3220\n",
      "Completed up until index: 3240\n",
      "Completed up until index: 3260\n",
      "Completed up until index: 3280\n",
      "Completed up until index: 3300\n",
      "Completed up until index: 3320\n",
      "Completed up until index: 3340\n",
      "Completed up until index: 3360\n",
      "Completed up until index: 3380\n",
      "Completed up until index: 3400\n",
      "Completed up until index: 3420\n",
      "Completed up until index: 3440\n",
      "Completed up until index: 3460\n",
      "Completed up until index: 3480\n",
      "Completed up until index: 3500\n",
      "Completed up until index: 3520\n",
      "Completed up until index: 3540\n",
      "Completed up until index: 3560\n",
      "Completed up until index: 3580\n",
      "Completed up until index: 3600\n",
      "Completed up until index: 3620\n",
      "Completed up until index: 3640\n",
      "Completed up until index: 3660\n",
      "Completed up until index: 3680\n",
      "Completed up until index: 3700\n",
      "Completed up until index: 3720\n",
      "Completed up until index: 3740\n",
      "Completed up until index: 3760\n",
      "Completed up until index: 3780\n",
      "Completed up until index: 3800\n",
      "Completed up until index: 3820\n",
      "Completed up until index: 3840\n",
      "Completed up until index: 3860\n",
      "Completed up until index: 3880\n",
      "Completed up until index: 3900\n",
      "Completed up until index: 3920\n",
      "Completed up until index: 3940\n",
      "Completed up until index: 3960\n",
      "Completed up until index: 3980\n",
      "Completed up until index: 4000\n",
      "Completed up until index: 4020\n",
      "Completed up until index: 4040\n",
      "Completed up until index: 4060\n",
      "Completed up until index: 4080\n",
      "Completed up until index: 4100\n",
      "Completed up until index: 4120\n",
      "Completed up until index: 4140\n",
      "Completed up until index: 4160\n",
      "Completed up until index: 4180\n",
      "Completed up until index: 4200\n",
      "Completed up until index: 4220\n",
      "Completed up until index: 4240\n",
      "Completed up until index: 4260\n",
      "Completed up until index: 4280\n",
      "Completed up until index: 4300\n",
      "Completed up until index: 4320\n",
      "Completed up until index: 4340\n",
      "Completed up until index: 4360\n",
      "Completed up until index: 4380\n",
      "Completed up until index: 4400\n",
      "Completed up until index: 4420\n",
      "Completed up until index: 4440\n",
      "Completed up until index: 4460\n",
      "Completed up until index: 4480\n",
      "Completed up until index: 4500\n",
      "Completed up until index: 4520\n",
      "Completed up until index: 4540\n",
      "Completed up until index: 4560\n",
      "Completed up until index: 4580\n",
      "Completed up until index: 4600\n",
      "Completed up until index: 4620\n",
      "Completed up until index: 4640\n",
      "Completed up until index: 4660\n",
      "Completed up until index: 4680\n",
      "Completed up until index: 4700\n",
      "Completed up until index: 4720\n",
      "Completed up until index: 4740\n",
      "Completed up until index: 4760\n",
      "Completed up until index: 4780\n",
      "Completed up until index: 4800\n",
      "Completed up until index: 4820\n",
      "Completed up until index: 4840\n",
      "Completed up until index: 4860\n",
      "Completed up until index: 4880\n",
      "Completed up until index: 4900\n",
      "Completed up until index: 4920\n",
      "Completed up until index: 4940\n",
      "Completed up until index: 4960\n",
      "Completed up until index: 4980\n",
      "Completed up until index: 5000\n",
      "Completed up until index: 5020\n",
      "Completed up until index: 5040\n",
      "Completed up until index: 5060\n",
      "Completed up until index: 5080\n",
      "Completed up until index: 5100\n",
      "Completed up until index: 5120\n",
      "Completed up until index: 5140\n",
      "Completed up until index: 5160\n",
      "Completed up until index: 5180\n",
      "Completed up until index: 5200\n",
      "Completed up until index: 5220\n",
      "Completed up until index: 5240\n",
      "Completed up until index: 5260\n",
      "Completed up until index: 5280\n",
      "Completed up until index: 5300\n",
      "Completed up until index: 5320\n",
      "Completed up until index: 5340\n",
      "Completed up until index: 5360\n",
      "Completed up until index: 5380\n",
      "Completed up until index: 5400\n",
      "Completed up until index: 5420\n",
      "Completed up until index: 5440\n",
      "Completed up until index: 5460\n",
      "Completed up until index: 5480\n",
      "Completed up until index: 5500\n",
      "Completed up until index: 5520\n",
      "Completed up until index: 5540\n",
      "Completed up until index: 5560\n",
      "Completed up until index: 5580\n",
      "Completed up until index: 5600\n",
      "Completed up until index: 5620\n",
      "Completed up until index: 5640\n",
      "Completed up until index: 5660\n",
      "Completed up until index: 5680\n",
      "Completed up until index: 5700\n",
      "Completed up until index: 5720\n",
      "Completed up until index: 5740\n",
      "Completed up until index: 5760\n",
      "Completed up until index: 5780\n",
      "Completed up until index: 5800\n",
      "Completed up until index: 5820\n",
      "Completed up until index: 5840\n",
      "Completed up until index: 5860\n",
      "Completed up until index: 5880\n",
      "Completed up until index: 5900\n",
      "Completed up until index: 5920\n",
      "Completed up until index: 5940\n",
      "Completed up until index: 5960\n",
      "Completed up until index: 5980\n",
      "Completed up until index: 6000\n",
      "Completed up until index: 6020\n",
      "Completed up until index: 6040\n",
      "Completed up until index: 6060\n",
      "Completed up until index: 6080\n",
      "Completed up until index: 6100\n",
      "Completed up until index: 6120\n",
      "Completed up until index: 6140\n",
      "Completed up until index: 6160\n",
      "Completed up until index: 6180\n",
      "Completed up until index: 6200\n",
      "Completed up until index: 6220\n",
      "Completed up until index: 6240\n",
      "Completed up until index: 6260\n",
      "Completed up until index: 6280\n",
      "Completed up until index: 6300\n",
      "Completed up until index: 6320\n",
      "Completed up until index: 6340\n",
      "Completed up until index: 6360\n",
      "Completed up until index: 6380\n",
      "Completed up until index: 6400\n",
      "Completed up until index: 6420\n",
      "Completed up until index: 6440\n",
      "Completed up until index: 6460\n",
      "Completed up until index: 6480\n",
      "Completed up until index: 6500\n",
      "Completed up until index: 6520\n",
      "Completed up until index: 6540\n",
      "Completed up until index: 6560\n",
      "Completed up until index: 6580\n",
      "Completed up until index: 6600\n",
      "Completed up until index: 6620\n",
      "Completed up until index: 6640\n",
      "Completed up until index: 6660\n",
      "Completed up until index: 6680\n",
      "Completed up until index: 6700\n",
      "Completed up until index: 6720\n",
      "Completed up until index: 6740\n",
      "Completed up until index: 6760\n",
      "Completed up until index: 6780\n",
      "Completed up until index: 6800\n",
      "Completed up until index: 6820\n",
      "Completed up until index: 6840\n",
      "Completed up until index: 6860\n",
      "Completed up until index: 6880\n",
      "Completed up until index: 6900\n",
      "Completed up until index: 6920\n",
      "Completed up until index: 6940\n",
      "Completed up until index: 6960\n",
      "Completed up until index: 6980\n",
      "Completed up until index: 7000\n",
      "Completed up until index: 7020\n",
      "Completed up until index: 7040\n",
      "Completed up until index: 7060\n",
      "Completed up until index: 7080\n",
      "Completed up until index: 7100\n",
      "Completed up until index: 7120\n",
      "Completed up until index: 7140\n",
      "Completed up until index: 7160\n",
      "Completed up until index: 7180\n",
      "Completed up until index: 7200\n",
      "Completed up until index: 7220\n",
      "Completed up until index: 7240\n",
      "Completed up until index: 7260\n",
      "Completed up until index: 7280\n",
      "Completed up until index: 7300\n",
      "Completed up until index: 7320\n",
      "Completed up until index: 7340\n",
      "Completed up until index: 7360\n",
      "Completed up until index: 7380\n",
      "Completed up until index: 7400\n",
      "Completed up until index: 7420\n",
      "Completed up until index: 7440\n",
      "Completed up until index: 7460\n",
      "Completed up until index: 7480\n",
      "Completed up until index: 7500\n",
      "Completed up until index: 7520\n",
      "Completed up until index: 7540\n",
      "Completed up until index: 7560\n",
      "Completed up until index: 7580\n",
      "Completed up until index: 7600\n",
      "Completed up until index: 7620\n",
      "Completed up until index: 7640\n",
      "Completed up until index: 7660\n",
      "Completed up until index: 7680\n",
      "Completed up until index: 7700\n",
      "Completed up until index: 7720\n",
      "Completed up until index: 7740\n",
      "Completed up until index: 7760\n",
      "Completed up until index: 7780\n",
      "Completed up until index: 7800\n",
      "Completed up until index: 7820\n",
      "Completed up until index: 7840\n",
      "Completed up until index: 7860\n",
      "Completed up until index: 7880\n"
     ]
    }
   ],
   "source": [
    "table_name = \"open_aq_locations\"\n",
    "\n",
    "## URI too large to insert more than about 20 rows at once, have to do in small sets\n",
    "kwargs = {\n",
    "    \"data_df\":locations,\n",
    "    \"batch_size\":20,\n",
    "    \"target_table_name\":table_name,\n",
    "    \"cols_and_types\":cols_and_types_locations,\n",
    "    \"cols_with_apostrophes\":[\"city\", \"location\", \"sourceName\"]\n",
    "}\n",
    "\n",
    "update_in_batches(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List OpenAQ locations that we've previously acknowledged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>firstupdated</th>\n",
       "      <th>iso3</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>sourcename</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40RL01 - ROESELARE</th>\n",
       "      <td>Flanders</td>\n",
       "      <td>2016-11-17T00:00:00Z</td>\n",
       "      <td>BEL</td>\n",
       "      <td>50.953180</td>\n",
       "      <td>3.121155</td>\n",
       "      <td>EEA Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40SZ01 - STEENOKKERZ</th>\n",
       "      <td>Flanders</td>\n",
       "      <td>2016-11-17T00:00:00Z</td>\n",
       "      <td>BEL</td>\n",
       "      <td>50.914577</td>\n",
       "      <td>4.504183</td>\n",
       "      <td>EEA Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40SZ02 - STEENOKKERZ</th>\n",
       "      <td>Flanders</td>\n",
       "      <td>2016-11-17T00:00:00Z</td>\n",
       "      <td>BEL</td>\n",
       "      <td>50.913020</td>\n",
       "      <td>4.512184</td>\n",
       "      <td>EEA Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40TS21 - TESSENDERLO</th>\n",
       "      <td>Flanders</td>\n",
       "      <td>2016-11-17T00:00:00Z</td>\n",
       "      <td>BEL</td>\n",
       "      <td>51.065710</td>\n",
       "      <td>5.107536</td>\n",
       "      <td>EEA Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40WZ02 - MOL</th>\n",
       "      <td>Flanders</td>\n",
       "      <td>2016-11-17T00:00:00Z</td>\n",
       "      <td>BEL</td>\n",
       "      <td>51.192800</td>\n",
       "      <td>5.221534</td>\n",
       "      <td>EEA Belgium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          city          firstupdated iso3   latitude  \\\n",
       "location                                                               \n",
       "40RL01 - ROESELARE    Flanders  2016-11-17T00:00:00Z  BEL  50.953180   \n",
       "40SZ01 - STEENOKKERZ  Flanders  2016-11-17T00:00:00Z  BEL  50.914577   \n",
       "40SZ02 - STEENOKKERZ  Flanders  2016-11-17T00:00:00Z  BEL  50.913020   \n",
       "40TS21 - TESSENDERLO  Flanders  2016-11-17T00:00:00Z  BEL  51.065710   \n",
       "40WZ02 - MOL          Flanders  2016-11-17T00:00:00Z  BEL  51.192800   \n",
       "\n",
       "                      longitude   sourcename  \n",
       "location                                      \n",
       "40RL01 - ROESELARE     3.121155  EEA Belgium  \n",
       "40SZ01 - STEENOKKERZ   4.504183  EEA Belgium  \n",
       "40SZ02 - STEENOKKERZ   4.512184  EEA Belgium  \n",
       "40TS21 - TESSENDERLO   5.107536  EEA Belgium  \n",
       "40WZ02 - MOL           5.221534  EEA Belgium  "
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_name = \"open_aq_locations\"\n",
    "select_all_sql = \"\"\"\n",
    "SELECT * FROM {table_name}\n",
    "\"\"\".format(table_name=table_name)\n",
    "\n",
    "res = sql_api(carto_url, select_all_sql, carto_api_token)\n",
    "locations = pd.DataFrame(res.json()[\"rows\"])\n",
    "locations = locations.set_index(\"location\")\n",
    "locations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve latest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = \"https://api.openaq.org/v1/latest\"\n",
    "\n",
    "params = {\n",
    "    \"limit\":10000\n",
    "}\n",
    "\n",
    "res = req.get(url, params=params)\n",
    "data = res.json()[\"results\"]\n",
    "\n",
    "latest_data = pd.io.json.json_normalize(data, ['measurements'],[['coordinates', 'latitude'], ['coordinates', 'longitude'],'location', 'city', 'country'],  \n",
    "                                          errors='ignore')\n",
    "\n",
    "##\n",
    "## Potential error - if no observed points have an averagingPeriod during an update, this can fail\n",
    "##\n",
    "\n",
    "latest_data.columns = [\"averagingPeriod\", \"lastUpdated\", \"parameter\", \"sourceName\", \"unit\", \"value\", \"latitude\", \"longitude\", \"location\",\"city\", \"country\"]\n",
    "latest_data[\"iso3\"] = iso2s.loc[latest_data[\"country\"], \"iso3\"].values\n",
    "latest_data = latest_data.set_index(\"location\")\n",
    "\n",
    "## May need to develop function for adding iso3 that is more flexible for a range of spellings...\n",
    "# Have a check whether anything was not successfully coded. Determine whether to add this new spelling\n",
    "# to running list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>averagingPeriod</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>parameter</th>\n",
       "      <th>sourceName</th>\n",
       "      <th>unit</th>\n",
       "      <th>value</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>iso3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100 ail</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-08T18:45:00.000Z</td>\n",
       "      <td>o3</td>\n",
       "      <td>Agaar.mn</td>\n",
       "      <td>g/m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.932907</td>\n",
       "      <td>106.92139</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>MNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100 ail</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-08T18:45:00.000Z</td>\n",
       "      <td>co</td>\n",
       "      <td>Agaar.mn</td>\n",
       "      <td>g/m</td>\n",
       "      <td>3656.0</td>\n",
       "      <td>47.932907</td>\n",
       "      <td>106.92139</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>MNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100 ail</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-08T18:45:00.000Z</td>\n",
       "      <td>pm10</td>\n",
       "      <td>Agaar.mn</td>\n",
       "      <td>g/m</td>\n",
       "      <td>269.0</td>\n",
       "      <td>47.932907</td>\n",
       "      <td>106.92139</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>MNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100 ail</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-08T18:45:00.000Z</td>\n",
       "      <td>so2</td>\n",
       "      <td>Agaar.mn</td>\n",
       "      <td>g/m</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.932907</td>\n",
       "      <td>106.92139</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>MNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100 ail</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-08T18:45:00.000Z</td>\n",
       "      <td>no2</td>\n",
       "      <td>Agaar.mn</td>\n",
       "      <td>g/m</td>\n",
       "      <td>78.0</td>\n",
       "      <td>47.932907</td>\n",
       "      <td>106.92139</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>MNG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         averagingPeriod               lastUpdated parameter sourceName  \\\n",
       "location                                                                  \n",
       "100 ail              NaN  2017-12-08T18:45:00.000Z        o3   Agaar.mn   \n",
       "100 ail              NaN  2017-12-08T18:45:00.000Z        co   Agaar.mn   \n",
       "100 ail              NaN  2017-12-08T18:45:00.000Z      pm10   Agaar.mn   \n",
       "100 ail              NaN  2017-12-08T18:45:00.000Z       so2   Agaar.mn   \n",
       "100 ail              NaN  2017-12-08T18:45:00.000Z       no2   Agaar.mn   \n",
       "\n",
       "           unit   value   latitude  longitude         city country iso3  \n",
       "location                                                                 \n",
       "100 ail   g/m     0.0  47.932907  106.92139  Ulaanbaatar      MN  MNG  \n",
       "100 ail   g/m  3656.0  47.932907  106.92139  Ulaanbaatar      MN  MNG  \n",
       "100 ail   g/m   269.0  47.932907  106.92139  Ulaanbaatar      MN  MNG  \n",
       "100 ail   g/m    47.0  47.932907  106.92139  Ulaanbaatar      MN  MNG  \n",
       "100 ail   g/m    78.0  47.932907  106.92139  Ulaanbaatar      MN  MNG  "
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see that new data all has a corresponding location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['100 ail', '16th and Whitmore', '1NL Navajo Lake', '21 de mayo',\n",
      "       '22nd Street & Craycr', '24th & O', '2912 Coffey', '2LL Los Lunas',\n",
      "       '40AB01 - ANTWERPEN', '40AB02 - BERENDRECHT',\n",
      "       ...\n",
      "       ':', ':', ': ', ': ',\n",
      "       ': ', ':', ': 1 ', ':1',\n",
      "       ':', 'Ban-Tai, Kanchanaburi'],\n",
      "      dtype='object', name='location', length=240)\n",
      "\n",
      "Total number of unique places in latest data: 8055\n",
      "Previously unseen places in latest data: 240\n"
     ]
    }
   ],
   "source": [
    "unique_places_in_latest_data = latest_data.index.unique()\n",
    "new_places_ix = [place not in locations.index for place in unique_places_in_latest_data]\n",
    "new_places = unique_places_in_latest_data[new_places_ix]\n",
    "print(new_places)\n",
    "\n",
    "### Replaced apostrophes, this could be a problem\n",
    "# Also dropped non-georeferenced\n",
    "# Follow up on both of these and see if there are still any unaccounted for\n",
    "\n",
    "print(\"\\nTotal number of unique places in latest data:\", len(unique_places_in_latest_data))\n",
    "print(\"Previously unseen places in latest data:\", len(new_places))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add any \"new places\" to the open_aq_locations table\n",
    "* Note: firstUpdated will be set to the earliest \"lastUpdated\" field for that sensor in the new data\n",
    "* This will likely not be correct... will need to verify this with OpenAQ partners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstUpdated</th>\n",
       "      <th>sourceName</th>\n",
       "      <th>city</th>\n",
       "      <th>iso3</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [firstUpdated, sourceName, city, iso3, latitude, longitude]\n",
       "Index: []"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_table_columns =[\"location\",\"firstUpdated\",\"sourceName\",\"city\",\"iso3\",\"latitude\",\"longitude\"]\n",
    "new_places_df = pd.DataFrame(columns=location_table_columns).set_index(\"location\")\n",
    "new_places_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>averagingPeriod</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>parameter</th>\n",
       "      <th>sourceName</th>\n",
       "      <th>unit</th>\n",
       "      <th>value</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>iso3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100 ail</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-08T10:45:00.000Z</td>\n",
       "      <td>o3</td>\n",
       "      <td>Agaar.mn</td>\n",
       "      <td>g/m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.932907</td>\n",
       "      <td>106.92139</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>MNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100 ail</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-08T10:45:00.000Z</td>\n",
       "      <td>pm10</td>\n",
       "      <td>Agaar.mn</td>\n",
       "      <td>g/m</td>\n",
       "      <td>203.0</td>\n",
       "      <td>47.932907</td>\n",
       "      <td>106.92139</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>MNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100 ail</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-08T10:45:00.000Z</td>\n",
       "      <td>so2</td>\n",
       "      <td>Agaar.mn</td>\n",
       "      <td>g/m</td>\n",
       "      <td>41.0</td>\n",
       "      <td>47.932907</td>\n",
       "      <td>106.92139</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>MNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100 ail</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-08T10:45:00.000Z</td>\n",
       "      <td>co</td>\n",
       "      <td>Agaar.mn</td>\n",
       "      <td>g/m</td>\n",
       "      <td>3771.0</td>\n",
       "      <td>47.932907</td>\n",
       "      <td>106.92139</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>MNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100 ail</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-08T10:45:00.000Z</td>\n",
       "      <td>no2</td>\n",
       "      <td>Agaar.mn</td>\n",
       "      <td>g/m</td>\n",
       "      <td>86.0</td>\n",
       "      <td>47.932907</td>\n",
       "      <td>106.92139</td>\n",
       "      <td>Ulaanbaatar</td>\n",
       "      <td>MN</td>\n",
       "      <td>MNG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         averagingPeriod               lastUpdated parameter sourceName  \\\n",
       "location                                                                  \n",
       "100 ail              NaN  2017-12-08T10:45:00.000Z        o3   Agaar.mn   \n",
       "100 ail              NaN  2017-12-08T10:45:00.000Z      pm10   Agaar.mn   \n",
       "100 ail              NaN  2017-12-08T10:45:00.000Z       so2   Agaar.mn   \n",
       "100 ail              NaN  2017-12-08T10:45:00.000Z        co   Agaar.mn   \n",
       "100 ail              NaN  2017-12-08T10:45:00.000Z       no2   Agaar.mn   \n",
       "\n",
       "           unit   value   latitude  longitude         city country iso3  \n",
       "location                                                                 \n",
       "100 ail   g/m     0.0  47.932907  106.92139  Ulaanbaatar      MN  MNG  \n",
       "100 ail   g/m   203.0  47.932907  106.92139  Ulaanbaatar      MN  MNG  \n",
       "100 ail   g/m    41.0  47.932907  106.92139  Ulaanbaatar      MN  MNG  \n",
       "100 ail   g/m  3771.0  47.932907  106.92139  Ulaanbaatar      MN  MNG  \n",
       "100 ail   g/m    86.0  47.932907  106.92139  Ulaanbaatar      MN  MNG  "
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_data.loc[new_places[0], ]\n",
    "\n",
    "locations.reset_index().set_index(\"city\").loc[\"Ulaanbaatar\"]\n",
    "latest_data.reset_index().set_index(\"city\").loc[\"Ulaanbaatar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load files to experiment with de-duping\n",
    "\n",
    "folder = \"/Users/nathansuberi/Desktop/RW_Data/open_aq/\"\n",
    "sample1_file = \"open_aq_latest_2017-12-07_09-19-10.csv\"\n",
    "sample2_file = \"open_aq_latest_2017-12-08_09-41-36.csv\"\n",
    "\n",
    "df1 = pd.read_csv(folder+sample1_file, index_col=[0])\n",
    "df2 = pd.read_csv(folder+sample2_file, index_col=[0])\n",
    "\n",
    "df1.set_index([\"latitude\", \"longitude\"], inplace=True)\n",
    "df2.set_index([\"latitude\", \"longitude\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Float64Index([-158.088592529,  -157.96913147,  -157.87109375, -157.858093262,\n",
       "              -156.492416382, -156.446105957, -156.370346069, -155.913299561,\n",
       "              -155.778137207, -155.468902588,\n",
       "              ...\n",
       "               153.028106689,  153.029998779,  153.032104492,  153.035003662,\n",
       "               153.087203979,  153.103805542,  153.135894775,  153.149505615,\n",
       "               153.152694702,  153.158096313],\n",
       "             dtype='float64', name='longitude', length=6183)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine if there are any overlaps\n",
    "df1.index.levels[0]\n",
    "df1.index.levels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Insert original data into Carto table\n",
    "# Insert value sql\n",
    "\n",
    "df = pd.read_csv(\"open_aq_latest_2017-12-08 09/21/31.219395.csv\")\n",
    "\n",
    "table_name = \"open_aq_history\"\n",
    "\n",
    "columns = str(tuple(df.columns)).replace(\"'\",\"\")\n",
    "values = \", \".join(list(df.apply(lambda row: dump_row_contents(row, cols_and_types_history), axis=1)))\n",
    "\n",
    "insert_value_sql = \"\"\"\n",
    "INSERT INTO {table_name} {columns} VALUES {values}\n",
    "\"\"\".format(table_name=table_name, columns=columns, values=values)\n",
    "\n",
    "print(insert_value_sql)\n",
    "\n",
    "res = sql_api(carto_url, insert_value_sql, carto_api_token)\n",
    "print(res.text)\n",
    "\n",
    "\n",
    "# Extract data from Carto table to run the de-duping method\n",
    "\n",
    "# Select all from a table in a certain time range\n",
    "\n",
    "## TO DO: Format this for the UTC format the Carto table will use\n",
    "look_back = \"1 day\"\n",
    "select_all_in_time_range_sql = \"\"\"\n",
    "SELECT * FROM {table_name} WHERE lastUpdated \n",
    "\"\"\".format(table_name=table_name)\n",
    "\n",
    "res = sql_api(carto_url, select_all_in_time_range_sql, carto_api_token)\n",
    "print(res.text)\n",
    "\n",
    "# Add in the de-duped data as an extension to the original Carto table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save latest data \n",
    "* Put on S3\n",
    "* Add into open_aq_history table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nathansuberi/Desktop/RW_Data/open_aq/open_aq_latest_2017-12-08_09-48-38.csv\n"
     ]
    }
   ],
   "source": [
    "# Current datetime, in desired format for naming convention\n",
    "cur_datetime = str(datetime.now())\n",
    "cur_datetime = cur_datetime.split(\".\")[0]\n",
    "cur_datetime = cur_datetime.replace(\":\", \"-\")\n",
    "cur_datetime = cur_datetime.replace(\" \", \"_\")\n",
    "\n",
    "folder = \"/Users/nathansuberi/Desktop/RW_Data/open_aq/\"\n",
    "file_name = \"open_aq_latest_{datetime}.csv\".format(datetime=cur_datetime)\n",
    "current_file_name = folder + file_name\\\n",
    "print(current_file_name)\n",
    "\n",
    "#df.to_csv(current_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['bc', 'co', 'no2', 'o3', 'pm10', 'pm25', 'so2'],\n",
       "       dtype='<U4'), array([   17,  3453, 24056,  6837,  4493,  2953,  4665]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## All of this made unnecessary by magic of json_normalize, but list flattening is a nice trick\n",
    "\n",
    "# # Extract measurements\n",
    "\n",
    "# # All possible measurements:\n",
    "# # Flattening nested lists: https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python\n",
    "# parameters = [obs[\"parameter\"] for msr in df['measurements'] for obs in msr]\n",
    "# parameters = np.unique(parameters, return_counts=True)\n",
    "# #(array(['bc', 'co', 'no2', 'o3', 'pm10', 'pm25', 'so2'],\n",
    "# #       dtype='<U4'), array([   17,  3453, 24056,  6837,  4493,  2953,  4665]))\n",
    "\n",
    "# # Sometimes has an averaging period, other times not\n",
    "# fields = [\"averagingPeriod\", \"lastUpdated\", \"parameter\", \"sourceName\", \"unit\", \"value\"]\n",
    "\n",
    "# parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-08 14:19:57.581782\n",
      "2017-12-08 09:19:57.582269\n",
      "1 day, 0:00:00\n",
      "2017-12-07 09:19:57.582608\n"
     ]
    }
   ],
   "source": [
    "# Exploring Python's datetime library\n",
    "# Docs: https://docs.python.org/3/library/datetime.html\n",
    "\n",
    "# This is UTC time, from Greenwich mean time\n",
    "print(datetime.utcnow())\n",
    "# This takes my current timezone\n",
    "print(datetime.now())\n",
    "# This makes a 1 day timedelta\n",
    "print(timedelta(days=1))\n",
    "print(datetime.now() - timedelta(days=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These two dfs are equal: True\n"
     ]
    }
   ],
   "source": [
    "# Experiment with breaking apart data structure\n",
    "x = np.random.rand(107)\n",
    "x = pd.DataFrame(x)\n",
    "#print(x)\n",
    "\n",
    "pieces = int(len(x) / piece_len)\n",
    "rg = range(pieces+1)\n",
    "y = pd.DataFrame([])\n",
    "\n",
    "for r in rg:\n",
    "    #print(r*piece_len)\n",
    "    #print(r*piece_len+piece_len)\n",
    "    y = y.append(x.iloc[r*piece_len:r*piece_len+piece_len], ignore_index=True)\n",
    "#y = np.append(y,x[pieces*piece_len:])\n",
    "\n",
    "print(\"These two dfs are equal:\",x.equals(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAQ API Documentation: https://docs.openaq.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cities\n",
    "url = \"https://api.openaq.org/v1/cities\"\n",
    "# Countries\n",
    "url = \"https://api.openaq.org/v1/countries\"\n",
    "# Fetches\n",
    "url = \"https://api.openaq.org/v1/fetches\"\n",
    "# Latest\n",
    "url = \"https://api.openaq.org/v1/latest\"\n",
    "# Locations\n",
    "url = \"https://api.openaq.org/v1/locations\"\n",
    "# Measurements\n",
    "url = \"https://api.openaq.org/v1/measurements\"\n",
    "# Parameters\n",
    "url = \"https://api.openaq.org/v1/parameters\"\n",
    "# Sources\n",
    "url = \"https://api.openaq.org/v1/sources\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
