{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cartoframes\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.max_rows = 200\n",
    "from datetime import datetime\n",
    "\n",
    "import requests as req\n",
    "import json\n",
    "import boto3\n",
    "from io import BytesIO, StringIO\n",
    "from gzip import GzipFile\n",
    "import gzip\n",
    "import boto3\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "import os\n",
    "logging.basicConfig(stream=sys.stderr, level=logging.DEBUG)\n",
    "import random\n",
    "\n",
    "import palettable\n",
    "\n",
    "from functools import reduce\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authenticate to RW API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "config = ConfigParser()\n",
    "config.read(\"/Users/nathansuberi/Desktop/WRI_Programming/cred/.env\")\n",
    "api_token = config.get(\"auth\", \"rw_api_token\")\n",
    "\n",
    "AUTH_TOKEN = api_token # <Insert Auth Token Here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authenticating to Carto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CARTO_USER = 'wri-rw'#os.environ.get('CARTO_USER')\n",
    "CARTO_KEY = ''#os.environ.get('CARTO_KEY')\n",
    "\n",
    "cc = cartoframes.CartoContext(base_url='https://{}.carto.com/'.format(CARTO_USER),\n",
    "                              api_key=CARTO_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authenticating to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aws_access_key_id = ''#os.environ.get('aws_access_key_id')\n",
    "aws_secret_access_key = ''#os.environ.get('aws_secret_access_key')\n",
    "\n",
    "s3_bucket = \"wri-public-data\"\n",
    "s3_folder = \"resourcewatch/georeffed/\"\n",
    "\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key\n",
    ")\n",
    "s3_resource = boto3.resource(\n",
    "    's3',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key\n",
    ")\n",
    "\n",
    "# Functions for reading and uploading data to/from S3\n",
    "def read_from_S3(bucket, key, index_col=0):\n",
    "    obj = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    df = pd.read_csv(BytesIO(obj['Body'].read()), index_col=[index_col], encoding=\"utf8\")\n",
    "    return(df)\n",
    "\n",
    "# client: https://gist.github.com/veselosky/9427faa38cee75cd8e27\n",
    "# resource: https://codereview.stackexchange.com/questions/107412/convert-zip-to-gzip-and-upload-to-s3-bucket\n",
    "# bucket: https://tobywf.com/2017/06/gzip-compression-for-boto3/\n",
    "def write_to_S3(df, bucket, key):\n",
    "    csv_buffer = StringIO()\n",
    "    # Need to set encoding in Python2... default of 'ascii' fails\n",
    "    df.to_csv(csv_buffer, encoding='utf-8')\n",
    "    s3_resource.Object(bucket, key).put(Body=csv_buffer.getvalue())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load georeferencing tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "georef = {\n",
    "    'geometry':cc.read('wri_countries_a'),\n",
    "    'aliases':cc.read('country_aliases_extended').drop(['index', 'the_geom'], axis=1),\n",
    "    'known_non_un_isos':cc.read('known_non_un_isos').drop(['index', 'the_geom'], axis=1)\n",
    "}\n",
    "\n",
    "georef['iso_aliases'] = georef['aliases'].drop('alias', axis=1).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data from WB API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Download Google Spreadsheets ####\n",
    "# Georeference Config\n",
    "!curl \"https://docs.google.com/spreadsheets/d/1Naqugy5wQEJQtGZzuNp0JU8WfeubRlRxGaBqgyQDvgg/export?format=tsv\" > wbg_config.tsv\n",
    "wbg_config = pd.read_csv(open(\"wbg_config.tsv\", \"r\"), sep=\"\\t\", index_col=None)\n",
    "os.remove(\"wbg_config.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wbg_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load_data_from_api('SP.POP.TOTL','National Population WBG')['National Population WBG'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data sets into memory for processing\n",
    "def load_data_from_api(wbg_id, ds_name):\n",
    "    res = req.get(\"http://api.worldbank.org/countries/all/indicators/{}?date=1999:2016&format=json&per_page=10000\".format(wbg_id))\n",
    "    data = pd.io.json.json_normalize(res.json()[1])\n",
    "    data = data[[\"country.value\", \"date\", \"value\"]]\n",
    "    data[\"value\"] = data[\"value\"].astype(float)\n",
    "    data[\"date\"] = [datetime.strptime(date, '%Y') for date in data['date']]\n",
    "    data.columns = [\"country_name\", \"year\", ds_name]\n",
    "    return data\n",
    "    \n",
    "def georef_by_cname(df):\n",
    "    # Weird behavior of globals in a local scope here:\n",
    "    # https://stackoverflow.com/questions/10851906/python-3-unboundlocalerror-local-variable-referenced-before-assignment\n",
    "    df.index = list(range(df.shape[0]))\n",
    "    df['join_col'] = df['country_name'].apply(lambda item: item.strip().lower().replace(' ','').replace('â€™', '\\''))\n",
    "    data_with_alias = df.merge(georef['aliases'],\n",
    "                       left_on='join_col',\n",
    "                       right_on='alias',\n",
    "                       how='left')\n",
    "    null_aliases = pd.isnull(data_with_alias['alias'])\n",
    "\n",
    "    if sum(null_aliases):\n",
    "        no_alias_match = data_with_alias[null_aliases]\n",
    "        logging.info('no match for these aliases in the data being processed: ')\n",
    "        missed_aliases = no_alias_match['country_name'].unique()\n",
    "        logging.info(missed_aliases)\n",
    "\n",
    "    logging.info('df shape: {}'.format(df.shape))\n",
    "    logging.info('data_with_alias shape: {}'.format(data_with_alias.shape))\n",
    "\n",
    "    df['rw_country_code'] = data_with_alias['iso'].values\n",
    "    df['rw_country_name'] = data_with_alias['name'].values\n",
    "    df = df.drop('join_col', axis=1)\n",
    "    return df\n",
    "\n",
    "def createHeaders():\n",
    "    return {\n",
    "        'content-type': \"application/json\",\n",
    "        'authorization': \"Bearer {}\".format( AUTH_TOKEN )\n",
    "    }\n",
    "\n",
    "def upload_data_to_cloud(df, cloud_name):\n",
    "    write_to_S3(df,s3_bucket,'{}{}.csv'.format(s3_folder,cloud_name))\n",
    "    print('saved {} georeffed data to s3'.format(cloud_name))\n",
    "    cc.write(df, cloud_name, overwrite=True, privacy='public')\n",
    "    print('saved {} georeffed data to Carto'.format(cloud_name))\n",
    "    \n",
    "def connect_to_rw_backoffice(cloud_name):\n",
    "    ds_specs = {\n",
    "        \"connectorType\":\"rest\",\n",
    "        \"provider\":\"cartodb\",\n",
    "        \"connectorUrl\":\"https://wri-rw.carto.com/tables/{}\".format(cloud_name),\n",
    "        \"application\":[\"rw\"],\n",
    "        \"name\":cloud_name\n",
    "    }\n",
    "\n",
    "    create_res = req.request(\"POST\", \n",
    "                      'https://api.resourcewatch.org/v1/dataset', \n",
    "                      data=json.dumps(ds_specs), \n",
    "                      headers = createHeaders())\n",
    "\n",
    "    logging.info(create_res)\n",
    "\n",
    "    return create_res.json()['data']['id']\n",
    "    \n",
    "    \n",
    "def setup_interaction_config(obj, col, ds):\n",
    "    _type = str(ds[col].dtype)\n",
    "    if _type == 'object':\n",
    "        _type = 'string'\n",
    "    if _type in ['int64', 'float64']:\n",
    "        _type = 'numeric'\n",
    "        \n",
    "    template = {'column': col,\n",
    "      'format': None,\n",
    "      'prefix': '',\n",
    "      'property': col,\n",
    "      'suffix': '',\n",
    "      'type': _type}\n",
    "    \n",
    "    obj.append(template)\n",
    "    return obj\n",
    "    \n",
    "def gen_sql(table_name, data_col):\n",
    "    basesql = ('SELECT wri.cartodb_id, ST_Transform(wri.the_geom, 3857)' +\n",
    "    ' AS the_geom_webmercator, data.rw_country_name, data.rw_country_code, data.country_name,' +\n",
    "    ' EXTRACT(YEAR FROM data.year) AS year,'+\n",
    "    ' data.{} FROM {} data'+\n",
    "    ' LEFT OUTER JOIN wri_countries_a wri' +\n",
    "    ' ON data.rw_country_code = wri.iso_a3' + \n",
    "    ' WHERE data.{} IS NOT NULL AND data.year=').format(data_col, table_name, data_col)\n",
    "    return basesql + '\\'{}\\''\n",
    "\n",
    "def pick_ramp(len_ramp):\n",
    "    '''Possibilities: ['Blues', 'BuGn', 'BuPu', 'GnBu', 'Greens', \n",
    "            'Greys', 'OrRd', 'Oranges', 'PuBu', 'PuBuGn', \n",
    "            'PuRd', 'Purples', 'RdPu', 'Reds', 'YlGn',\n",
    "           'YlGnBu', 'YlOrBr', 'YlOrRd']'''\n",
    "    poss_colors = list(palettable.colorbrewer.sequential.__dict__.keys())\n",
    "    # Don't accept the reverse ramps\n",
    "    poss_colors = [col for col in poss_colors if (col[-1] == str(len_ramp))]\n",
    "    ramp = random.choice(poss_colors)\n",
    "    colors = palettable.colorbrewer.sequential.__dict__[ramp].hex_colors\n",
    "    return colors\n",
    "\n",
    "def gen_cartocss_legend(col, breaks, colors):\n",
    "    cartocss = '#table {polygon-opacity: 1; line-width: 0.5; line-color: #FFF; line-opacity: 1;}'\n",
    "    #cartocss += ' [{} > {}]?1polygon-fill:{} ;?2'.format(col,breaks[0],colors[0])\n",
    "    legend = []#[{'color':colors[0], 'name':'>{}'.format(breaks[0])}]\n",
    "    for i in range(0,len(breaks)-1):\n",
    "        cartocss += ' [{} > {}][{} < {}]?1polygon-fill:{} ;?2'.format(col,breaks[i],col,breaks[i+1],colors[i])\n",
    "        legend.append({'color':colors[i], 'name':'<{}'.format(breaks[i+1])})\n",
    "    cartocss = cartocss.replace('?1', '{').replace('?2', '}')\n",
    "\n",
    "    return cartocss, legend\n",
    "    \n",
    "def autogen_layer_def(year, max_year, rw_id, cloud_name, cartocss, legend, interaction, basesql):  \n",
    "    str_year = str(year)[:4]\n",
    "    str_maxyear = str(max_year)[:4]\n",
    "    layer_name = '{}_{}'.format(cloud_name, str_year)\n",
    "    layer_name = ' '.join(layer_name.split('_')[2:]).title()\n",
    "    layer_template = {\n",
    "          'application': ['rw'],\n",
    "          'language':'en',\n",
    "          'applicationConfig': {},\n",
    "          'dataset': rw_id,\n",
    "          'default': True if str_year == str_maxyear else False,\n",
    "          'description': '',\n",
    "          'env': 'production',\n",
    "          'interactionConfig': {\n",
    "              'output':interaction\n",
    "            },\n",
    "            'geoInfo':True,\n",
    "            'type':'tabular',\n",
    "          'iso': [],\n",
    "          'layerConfig': {'account': 'wri-rw',\n",
    "           'body': {'layers': [{'options': {'cartocss': cartocss,\n",
    "               'cartocss_version': '2.3.0',\n",
    "               'sql': basesql.format(year)},\n",
    "              'type': 'mapnik'}],\n",
    "            'maxzoom': 18,\n",
    "            'minzoom': 3}},\n",
    "          'legendConfig': {'items': legend,\n",
    "           'type': 'choropleth'},\n",
    "          'name': layer_name,\n",
    "          'protected': False,\n",
    "          'provider': 'cartodb'\n",
    "    }\n",
    "    \n",
    "    \n",
    "    layer_template['layerConfig']['timeline'] = True\n",
    "    layer_template['layerConfig']['order'] = int(str_year)\n",
    "    layer_template['layerConfig']['timelineLabel'] = str(str_year)\n",
    "   \n",
    "    return layer_template\n",
    "        \n",
    "def upload_layer_def_to_backoffice(layer_def, rw_id):\n",
    "    url = \"https://api.resourcewatch.org/v1/dataset/{}/layer\" .format(rw_id)\n",
    "    res = req.request(\"POST\", url, data=json.dumps(layer_def), headers = createHeaders())\n",
    "    return res.text\n",
    "    \n",
    "def load_tags_to_backoffice(tags, rw_id):\n",
    "    # Here, 'general' is a 'vocabulary id'\n",
    "    tags = tags.split(';')\n",
    "    url = \"https://api.resourcewatch.org/v1/dataset/{}/vocabulary/general\" .format(rw_id)\n",
    "    res = req.request(\"POST\", url, data=json.dumps({'tags':tags}), headers = createHeaders())\n",
    "    return res.text\n",
    "    \n",
    "def prepare_data(obj, info):\n",
    "    wri_id = info[0]\n",
    "    wbg_id = info[1]\n",
    "    ds_name = info[2].replace(' ', '_').lower()\n",
    "    cloud_name = '{}_{}'.format(wri_id, ds_name).replace('.', '_')\n",
    "    units = info[3] # not currently in use\n",
    "    tags = info[4] # not currently in use\n",
    "    _format = info[5] # not currently in use\n",
    "    num_breaks = 7\n",
    "    \n",
    "    wbg_ds = load_data_from_api(wbg_id, ds_name)\n",
    "    wbg_ds_georef = georef_by_cname(wbg_ds)\n",
    "    \n",
    "    upload_data_to_cloud(wbg_ds_georef, cloud_name)\n",
    "    rw_id = connect_to_rw_backoffice(cloud_name)\n",
    "    \n",
    "    # Make breaks by quintile\n",
    "    q0 = 0#wbg_ds_georef[ds_name].quantile(0)\n",
    "    q20 = 20#wbg_ds_georef[ds_name].quantile(.20)\n",
    "    q40 = 40#wbg_ds_georef[ds_name].quantile(.40)\n",
    "    q60 = 60#wbg_ds_georef[ds_name].quantile(.60)\n",
    "    q80 = 80#wbg_ds_georef[ds_name].quantile(.80)\n",
    "    q100 = 100#wbg_ds_georef[ds_name].quantile(1.00)\n",
    "    breaks = [q0,q20,q40,q60,q80,q100]\n",
    "    colors = pick_ramp(len(breaks)+1)\n",
    "    \n",
    "    cartocss, legend = gen_cartocss_legend(ds_name, breaks, colors)\n",
    "    interaction = reduce(lambda obj, col: setup_interaction_config(obj, col, wbg_ds_georef), wbg_ds_georef.columns, [])\n",
    "    basesql = gen_sql(cloud_name, ds_name)\n",
    "    max_year = wbg_ds_georef['year'].max()\n",
    "    layer_defs = list(map(lambda year: autogen_layer_def(year, max_year, rw_id, cloud_name, cartocss, legend, interaction, basesql), wbg_ds_georef['year'].unique()))\n",
    "    logging.info(layer_defs)\n",
    "    \n",
    "    layer_defs_on_backoffice = list(map(lambda ldef: upload_layer_def_to_backoffice(ldef, rw_id), layer_defs))\n",
    "    logging.info(layer_defs_on_backoffice)\n",
    "    #vocab_on_backoffice = load_tags_to_backoffice(tags, rw_id)\n",
    "    #logging.info(vocab_on_backoffice)\n",
    "    obj[wri_id] = {\n",
    "        'rw_id':rw_id,\n",
    "        'data':wbg_ds_georef,\n",
    "        'layers':layer_defs_on_backoffice,\n",
    "        'tags':None #vocab_on_backoffice\n",
    "    }\n",
    "    \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_tables = reduce(prepare_data, wbg_config.values, {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine uploaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "links = [(k, 'https://staging.resourcewatch.org/data/explore/{}'.format(v['rw_id'])) for k, v in data_tables.items()]\n",
    "list(map(lambda t: print(t[0], t[1]), links))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
