{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Handling carto data\n",
    "import cartoframes\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.max_rows = 200\n",
    "\n",
    "# Requesting data from the web\n",
    "import requests as req\n",
    "import json\n",
    "\n",
    "# Getting data on s3\n",
    "import boto3\n",
    "from io import BytesIO, StringIO\n",
    "from gzip import GzipFile\n",
    "import gzip\n",
    "import boto3\n",
    "\n",
    "# Logging\n",
    "import sys\n",
    "import logging\n",
    "import os\n",
    "logging.basicConfig(stream=sys.stderr, level=logging.INFO)\n",
    "\n",
    "# Creating ColorBrewer palettes for quick visualization\n",
    "import palettable\n",
    "\n",
    "# Often useful tools\n",
    "from datetime import timedelta, datetime\n",
    "from functools import reduce\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from hurry.filesize import size, si, verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper script - set environ variables locally"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Run this script in the same terminal window as running the \"jupyter notebook\" command, before you run it! Otherwise the env variables won't be available to this notebook.\n",
    "\n",
    "for line in $(cat /Users/nathansuberi/Documents/cred/.env_local); do\n",
    "if [[ $line == *=* ]]; then export $line; fi;\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authenticate to RW API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AUTH_TOKEN = os.environ.get(\"rw_api_token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authenticating to Carto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CARTO_USER = os.environ.get('CARTO_WRI_RW_USER')\n",
    "CARTO_KEY = os.environ.get('CARTO_WRI_RW_KEY')\n",
    "\n",
    "cc = cartoframes.CartoContext(base_url='https://{}.carto.com/'.format(CARTO_USER),\n",
    "                              api_key=CARTO_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authenticating to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S3_KEY_ID = os.environ.get('aws_access_key_id')\n",
    "S3_KEY = os.environ.get('aws_secret_access_key')\n",
    "\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=S3_KEY_ID,\n",
    "    aws_secret_access_key=S3_KEY\n",
    ")\n",
    "s3_resource = boto3.resource(\n",
    "    's3',\n",
    "    aws_access_key_id=S3_KEY_ID,\n",
    "    aws_secret_access_key=S3_KEY\n",
    ")\n",
    "\n",
    "# Functions for reading and uploading data to/from S3\n",
    "def read_from_S3(bucket, key, index_col=0):\n",
    "    obj = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    df = pd.read_csv(BytesIO(obj['Body'].read()), index_col=[index_col], encoding=\"utf8\")\n",
    "    return(df)\n",
    "\n",
    "# client: https://gist.github.com/veselosky/9427faa38cee75cd8e27\n",
    "# resource: https://codereview.stackexchange.com/questions/107412/convert-zip-to-gzip-and-upload-to-s3-bucket\n",
    "# bucket: https://tobywf.com/2017/06/gzip-compression-for-boto3/\n",
    "def write_to_S3(df, bucket, key):\n",
    "    csv_buffer = StringIO()\n",
    "    # Need to set encoding in Python2... default of 'ascii' fails\n",
    "    df.to_csv(csv_buffer, encoding='utf-8')\n",
    "    s3_resource.Object(bucket, key).put(Body=csv_buffer.getvalue())\n",
    "    \n",
    "\n",
    "#https://alexwlchan.net/2017/07/listing-s3-keys/\n",
    "\n",
    "def get_matching_s3_keys(bucket, prefix='', suffix=''):\n",
    "    \"\"\"\n",
    "    Generate the keys in an S3 bucket.\n",
    "\n",
    "    :param bucket: Name of the S3 bucket.\n",
    "    :param prefix: Only fetch keys that start with this prefix (optional).\n",
    "    :param suffix: Only fetch keys that end with this suffix (optional).\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "    kwargs = {'Bucket': bucket}\n",
    "\n",
    "    # If the prefix is a single string (not a tuple of strings), we can\n",
    "    # do the filtering directly in the S3 API.\n",
    "    if isinstance(prefix, str):\n",
    "        kwargs['Prefix'] = prefix\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # The S3 API response is a large blob of metadata.\n",
    "        # 'Contents' contains information about the listed objects.\n",
    "        resp = s3.list_objects_v2(**kwargs)\n",
    "        for obj in resp['Contents']:\n",
    "            key = obj['Key']\n",
    "            size = obj['Size']\n",
    "            if key.startswith(prefix) and key.endswith(suffix):\n",
    "                yield key, size\n",
    "\n",
    "        # The S3 API is paginated, returning up to 1000 keys at a time.\n",
    "        # Pass the continuation token into the next response, until we\n",
    "        # reach the final page (when this field is missing).\n",
    "        try:\n",
    "            kwargs['ContinuationToken'] = resp['NextContinuationToken']\n",
    "        except KeyError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bucket_list = s3_client.list_buckets()\n",
    "buckets = [bucket[\"Name\"] for bucket in bucket_list[\"Buckets\"]]\n",
    "#print(\"Bucket List:\", buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_vector_objects = list(get_matching_s3_keys(bucket='wri-public-data', prefix='resourcewatch/', suffix='.zip'))\n",
    "\n",
    "vector_summary = pd.DataFrame(all_vector_objects)#[['Key','Size']]\n",
    "vector_summary.columns = ['Key','Size']\n",
    "vector_summary = vector_summary.sort_values(by='Size', axis=0, ascending=False)\n",
    "\n",
    "vector_summary['Size'] = vector_summary.apply(lambda row: size(row['Size'], system=verbose), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chinese_aiddata = pd.read_excel('/Users/nathansuberi/Desktop/RW_Data/GlobalChineseOfficialFinanceDataset_v1.0/GlobalChineseOfficialFinanceDataset_v1.0.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chinese_aiddata.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Georeference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ISO_ALIAS_INFO = cc.read('country_aliases_extended')\n",
    "ISO_ALIAS_INFO = ISO_ALIAS_INFO.drop(['alias', 'index', 'the_geom'], axis=1).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def georef_by_ccode(df, ccode):\n",
    "    # Weird behavior of globals in a local scope here:\n",
    "    # https://stackoverflow.com/questions/10851906/python-3-unboundlocalerror-local-variable-referenced-before-assignment\n",
    "    df.index = list(range(df.shape[0]))\n",
    "    data_with_alias = df.merge(ISO_ALIAS_INFO,\n",
    "                       left_on=ccode,\n",
    "                       right_on='iso',\n",
    "                       how='left')\n",
    "    try:\n",
    "        null_isos = pd.isnull(data_with_alias['iso'])\n",
    "    except:\n",
    "        null_isos = pd.isnull(data_with_alias['iso_y'])\n",
    "\n",
    "    if sum(null_isos):\n",
    "        no_iso_match = data_with_alias[null_isos]\n",
    "        logging.info('no match for these isos in the data being processed: ')\n",
    "        try:\n",
    "            missed_isos = no_iso_match[ccode].unique()\n",
    "            logging.info(missed_isos)\n",
    "        except:\n",
    "            ccode = ccode +'_x'\n",
    "            missed_isos = no_iso_match[ccode].unique()\n",
    "            logging.info(missed_isos)\n",
    "\n",
    "    logging.info('df shape: {}'.format(df.shape))\n",
    "    logging.info('data_with_alias shape: {}'.format(data_with_alias.shape))\n",
    "\n",
    "    try:\n",
    "        df['rw_country_code'] = data_with_alias['iso'].values\n",
    "    except:\n",
    "        df['rw_country_code'] = data_with_alias['iso_y'].values\n",
    "    try:\n",
    "        df['rw_country_name'] = data_with_alias['name']\n",
    "    except:\n",
    "        df['rw_country_name'] = data_with_alias['name_y']\n",
    "\n",
    "    # Enforce correct ordering of columns here\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chinese_aiddata = georef_by_ccode(chinese_aiddata, 'recipient_iso3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean spaces in the val column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This was causing a problem with the sum(usd_current) part of the SQL, \n",
    "# saying it couldn't sum a text field\n",
    "inspect = [type(val)==str for val in chinese_aiddata['usd_current']]\n",
    "chinese_aiddata.loc[inspect, 'usd_current'] = None\n",
    "\n",
    "# This didn't work - I ended up changing the column type directly in Carto to numeric, \n",
    "# which forced the nulls as I expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to Carto and S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table_name = 'com_032_chinese_investments_abroad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cc.write(chinese_aiddata, table_name, overwrite=True, privacy='public')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_to_S3(chinese_aiddata, 'wri-public-data', 'resourcewatch/{}.csv'.format(table_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to Back Office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createHeaders():\n",
    "    return {\n",
    "        'content-type': \"application/json\",\n",
    "        'authorization': \"Bearer {}\".format( AUTH_TOKEN )\n",
    "    }\n",
    "\n",
    "def connect_to_rw_backoffice(cloud_name):\n",
    "    ds_specs = {\n",
    "        \"connectorType\":\"rest\",\n",
    "        \"provider\":\"cartodb\",\n",
    "        \"connectorUrl\":\"https://wri-rw.carto.com/tables/{}\".format(cloud_name),\n",
    "        \"application\":[\"rw\"],\n",
    "        \"name\":cloud_name\n",
    "    }\n",
    "\n",
    "    create_res = req.request(\"POST\", \n",
    "                      'https://api.resourcewatch.org/v1/dataset', \n",
    "                      data=json.dumps(ds_specs), \n",
    "                      headers = createHeaders())\n",
    "\n",
    "    logging.info(create_res.text)\n",
    "\n",
    "    return create_res.json()['data']['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rw_id = connect_to_rw_backoffice(table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rw_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create visualization w/ interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_basesql(table_name):\n",
    "    basesql = ('SELECT wri.cartodb_id, ST_Transform(wri.the_geom, 3857) AS the_geom_webmercator,' + \n",
    "    ' data.rw_country_name, data.rw_country_code, data.year, data.sum_val FROM '+\n",
    "    ' (SELECT rw_country_name, rw_country_code, year, sum(usd_current) as sum_val FROM {}' + \n",
    "    ' GROUP BY recipient_iso3, rw_country_name, rw_country_code, year) data' +\n",
    "    ' LEFT OUTER JOIN wri_countries_a wri' +\n",
    "    ' ON data.rw_country_code = wri.iso_a3' + \n",
    "    ' WHERE data.year=').format(table_name)\n",
    "    return basesql + '{}'\n",
    "\n",
    "def setup_interaction_config(obj, col, ds):\n",
    "    _type = str(ds[col].dtype)\n",
    "    if _type == 'object':\n",
    "        _type = 'string'\n",
    "    if _type in ['int64', 'float64']:\n",
    "        _type = 'numeric'\n",
    "        \n",
    "    template = {'column': col,\n",
    "      'format': None,\n",
    "      'prefix': '',\n",
    "      'property': col,\n",
    "      'suffix': '',\n",
    "      'type': _type}\n",
    "    \n",
    "    obj.append(template)\n",
    "    return obj\n",
    "    \n",
    "def pick_ramp(len_ramp, ramp_colors = None):\n",
    "    '''Possibilities: ['Blues', 'BuGn', 'BuPu', 'GnBu', 'Greens', \n",
    "            'Greys', 'OrRd', 'Oranges', 'PuBu', 'PuBuGn', \n",
    "            'PuRd', 'Purples', 'RdPu', 'Reds', 'YlGn',\n",
    "           'YlGnBu', 'YlOrBr', 'YlOrRd']'''\n",
    "    if not ramp_colors:\n",
    "        poss_colors = list(palettable.colorbrewer.sequential.__dict__.keys())\n",
    "        # Don't accept the reverse ramps\n",
    "        poss_colors = [col for col in poss_colors if (col[-1] == str(len_ramp))]\n",
    "        ramp = random.choice(poss_colors)\n",
    "    else:\n",
    "        ramp = '{}_{}'.format(ramp_colors, len_ramp)\n",
    "        \n",
    "    colors = palettable.colorbrewer.sequential.__dict__[ramp].hex_colors\n",
    "    \n",
    "    return colors\n",
    "\n",
    "def gen_cartocss_legend(col, breaks, colors):\n",
    "    cartocss = '#table {polygon-opacity: 1; line-width: 0.5; line-color: #FFF; line-opacity: 1;}'\n",
    "    #cartocss += ' [{} > {}]?1polygon-fill:{} ;?2'.format(col,breaks[0],colors[0])\n",
    "    legend = []#[{'color':colors[0], 'name':'>{}'.format(breaks[0])}]\n",
    "    for i in range(0,len(breaks)-1):\n",
    "        cartocss += ' [{} > {}][{} < {}]?1polygon-fill:{} ;?2'.format(col,breaks[i],col,breaks[i+1],colors[i])\n",
    "        legend.append({'color':colors[i], 'name':'<{}'.format(breaks[i+1])})\n",
    "    cartocss = cartocss.replace('?1', '{').replace('?2', '}')\n",
    "\n",
    "    return cartocss, legend\n",
    "    \n",
    "def autogen_layer_def(year, min_year, rw_id, cloud_name, cartocss, legend, interaction, basesql):  \n",
    "    str_year = str(year)[:4]\n",
    "    str_minyear = str(min_year)[:4]\n",
    "    layer_name = '{}_{}'.format(cloud_name, str_year)\n",
    "    layer_name = ' '.join(layer_name.split('_')[2:]).title()\n",
    "    layer_template = {\n",
    "          'application': ['rw'],\n",
    "          'language':'en',\n",
    "          'applicationConfig': {},\n",
    "          'dataset': rw_id,\n",
    "          'default': True if str_year == str_minyear else False,\n",
    "          'description': '',\n",
    "          'env': 'production',\n",
    "          'interactionConfig': {\n",
    "              'output':{}#interaction\n",
    "            },\n",
    "            'geoInfo':True,\n",
    "            'type':'tabular',\n",
    "          'iso': [],\n",
    "          'layerConfig': {'account': 'wri-rw',\n",
    "           'body': {'layers': [{'options': {'cartocss': cartocss,\n",
    "               'cartocss_version': '2.3.0',\n",
    "               'sql': basesql.format(year)},\n",
    "              'type': 'mapnik'}],\n",
    "            'maxzoom': 18,\n",
    "            'minzoom': 3}},\n",
    "          'legendConfig': {'items': legend,\n",
    "           'type': 'choropleth'},\n",
    "          'name': layer_name,\n",
    "          'protected': False,\n",
    "          'provider': 'cartodb'\n",
    "    }\n",
    "    \n",
    "    layer_template['layerConfig']['timeline'] = True\n",
    "    layer_template['layerConfig']['order'] = int(str_year)\n",
    "    layer_template['layerConfig']['timelineLabel'] = str(str_year)\n",
    "   \n",
    "    return layer_template\n",
    "        \n",
    "def upload_layer_def_to_backoffice(layer_def, rw_id):\n",
    "    url = \"https://api.resourcewatch.org/v1/dataset/{}/layer\" .format(rw_id)\n",
    "    res = req.request(\"POST\", url, data=json.dumps(layer_def), headers = createHeaders())\n",
    "    return res.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "breaks = [0, 100000, 1000000, 1000000000, 10000000000, 100000000000]\n",
    "colors = pick_ramp(len(breaks)+1, 'Greens')\n",
    "TABLE_NAME = table_name\n",
    "DF = chinese_aiddata\n",
    "VAL_COL = 'sum_val'\n",
    "YEAR_COL = 'year'\n",
    "\n",
    "basesql = gen_basesql(TABLE_NAME)\n",
    "\n",
    "cartocss, legend = gen_cartocss_legend(VAL_COL, breaks, colors)\n",
    "#interaction = reduce(lambda obj, col: setup_interaction_config(obj, col, DF), DF.columns, [])\n",
    "min_year = DF[YEAR_COL].min()\n",
    "layer_defs = list(map(lambda year: autogen_layer_def(year, min_year, rw_id, TABLE_NAME, cartocss, legend, interaction, basesql), DF[YEAR_COL].unique()))\n",
    "logging.debug(layer_defs)\n",
    "\n",
    "layer_defs_on_backoffice = list(map(lambda ldef: upload_layer_def_to_backoffice(ldef, rw_id), layer_defs))\n",
    "logging.debug(layer_defs_on_backoffice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_dataset_and_layers(wri_id):\n",
    "    list_layers_res = req.request(\"GET\", \n",
    "                      'https://api.resourcewatch.org/v1/dataset/{}/layer'.format(wri_id))\n",
    "    layers = list_layers_res.json()['data']\n",
    "    layer_ids = [l['id'] for l in layers]\n",
    "        \n",
    "    deleted_layers = []\n",
    "    for l_id in layer_ids:\n",
    "        delete_layer = req.request(\"DELETE\", \n",
    "                      'https://api.resourcewatch.org/v1/dataset/{}/layer/{}'.format(wri_id, l_id),\n",
    "                       headers = createHeaders())\n",
    "        \n",
    "        deleted_layers.append(delete_layer.text)\n",
    "    \n",
    "    deleted_dataset = req.request(\"DELETE\", \n",
    "                      'https://api.resourcewatch.org/v1/dataset/{}'.format(wri_id),\n",
    "                       headers = createHeaders())\n",
    "    \n",
    "    return deleted_dataset.text, deleted_layers\n",
    "\n",
    "remove_dataset_and_layers(rw_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
