{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests as req\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "logging.basicConfig(stream=sys.stderr, level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authenticate to RW API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "config = ConfigParser()\n",
    "config.read(\"/Users/nathansuberi/Desktop/WRI_Programming/cred/.env\")\n",
    "api_token = config.get(\"auth\", \"rw_api_token\")\n",
    "\n",
    "AUTH_TOKEN = api_token # <Insert Auth Token Here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing current data set \n",
    "Goal is to switch all widgets from this old data set to a new one with a different table name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rw_id = 'c61c364b-1d68-4dd9-ae3d-76c2a0022280'\n",
    "\n",
    "# Base URL for getting dataset metadata from RW API\n",
    "url = \"https://api.resourcewatch.org/v1/dataset/{rw_id}?sort=slug,-provider,userId&status=saved&includes=metadata,vocabulary,widget,layer\"\n",
    "url = url.format(rw_id = rw_id)\n",
    "# page[size] tells the API the maximum number of results to send back\n",
    "# There are currently between 200 and 300 datasets on the RW API\n",
    "payload = { \"application\":\"rw\", \"page[size]\": 1000}\n",
    "\n",
    "# Request all datasets, and extract the data from the response\n",
    "res = req.get(url, params=payload)\n",
    "try:\n",
    "    data = res.json()[\"data\"]\n",
    "except:\n",
    "    raise Exception('No data available')\n",
    "    \n",
    "### Convert the json object returned by the API into a pandas DataFrame\n",
    "atts = data[\"attributes\"]\n",
    "metadata = atts[\"metadata\"]\n",
    "layers = atts[\"layer\"]\n",
    "widgets = atts[\"widget\"]\n",
    "tags = atts[\"vocabulary\"]\n",
    "\n",
    "api_info = {\n",
    "    \"name\":atts[\"name\"],\n",
    "    \"table_name\":atts[\"tableName\"],\n",
    "    \"provider\":atts[\"provider\"],\n",
    "    \"date_updated\":atts[\"updatedAt\"],\n",
    "    \"num_metadata\":len(metadata),\n",
    "    \"metadata\": metadata,\n",
    "    \"num_layers\":len(layers),\n",
    "    \"layers\": layers,\n",
    "    \"num_widgets\":len(widgets),\n",
    "    \"widgets\": widgets,\n",
    "    \"num_tags\":len(tags),\n",
    "    \"tags\":tags\n",
    "}\n",
    "\n",
    "# Create the DataFrame, name the index, and sort by date_updated\n",
    "# More recently updated datasets at the top\n",
    "old_ds_info = pd.DataFrame.from_dict(api_info, orient='index')\n",
    "old_ds_info.columns = [rw_id]\n",
    "old_table_name = old_ds_info.loc['table_name'].values[0]\n",
    "old_ds_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dataset using API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'content-type': \"application/json\",\n",
    "    'authorization': \"Bearer {}\".format( AUTH_TOKEN )\n",
    "}\n",
    "\n",
    "ds_specs = {\n",
    "    \"connectorType\":\"rest\",\n",
    "    \"provider\":\"cartodb\",\n",
    "    \"connectorUrl\":\"https://wri-rw.carto.com/tables/com_009_flowmfa\",\n",
    "    \"application\":[\"rw\"],\n",
    "    \"name\":\"Material Extraction, Trade, and Use\"\n",
    "}\n",
    "\n",
    "create_res = req.request(\"POST\", \n",
    "                  'https://api.resourcewatch.org/v1/dataset', \n",
    "                  data=json.dumps(ds_specs), \n",
    "                  headers = headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds_res = create_res.json()['data']\n",
    "\n",
    "new_rw_id = ds_res['id']\n",
    "new_table_name = ds_res['attributes']['tableName']\n",
    "\n",
    "ds_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"https://api.resourcewatch.org/v1/dataset/{rw_id}/{endpoint}\"  \n",
    "\n",
    "for metadata in old_ds_info.loc['metadata'].values[0]:\n",
    "    metadata['attributes']['language'] = 'en'\n",
    "    metadata['attributes']['application'] = 'rw'\n",
    "    print(metadata['attributes'])\n",
    "    _url = url.format(rw_id = new_rw_id, endpoint = 'metadata')\n",
    "    res = req.request(\"POST\", _url, data=json.dumps(metadata['attributes']), headers = headers)\n",
    "    logging.info(res.text)    \n",
    "        \n",
    "for widget in old_ds_info.loc['widgets'].values[0]:\n",
    "    widget['attributes']['application'] = ['rw']\n",
    "    widget['attributes']['language'] = 'en'\n",
    "    _url = url.format(rw_id = new_rw_id, endpoint = 'widget')\n",
    "    res = req.request(\"POST\", _url, data=json.dumps(widget['attributes']), headers = headers)\n",
    "    logging.info(res.text)   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logging.info('OLD ID: {}'.format(rw_id))\n",
    "logging.info('NEW ID: {}'.format(new_rw_id))\n",
    "\n",
    "\n",
    "# Base URL for getting dataset metadata from RW API\n",
    "url = \"https://api.resourcewatch.org/v1/dataset/{rw_id}?sort=slug,-provider,userId&status=saved&includes=metadata,vocabulary,widget,layer\"\n",
    "url = url.format(rw_id = new_rw_id)\n",
    "# page[size] tells the API the maximum number of results to send back\n",
    "# There are currently between 200 and 300 datasets on the RW API\n",
    "payload = { \"application\":\"rw\", \"page[size]\": 1000}\n",
    "\n",
    "# Request all datasets, and extract the data from the response\n",
    "res = req.get(url, params=payload)\n",
    "try:\n",
    "    data = res.json()[\"data\"]\n",
    "except:\n",
    "    raise Exception('No data available')\n",
    "    \n",
    "### Convert the json object returned by the API into a pandas DataFrame\n",
    "atts = data[\"attributes\"]\n",
    "metadata = atts[\"metadata\"]\n",
    "layers = atts[\"layer\"]\n",
    "widgets = atts[\"widget\"]\n",
    "tags = atts[\"vocabulary\"]\n",
    "\n",
    "api_info = {\n",
    "    \"name\":atts[\"name\"],\n",
    "    \"table_name\":atts[\"tableName\"],\n",
    "    \"provider\":atts[\"provider\"],\n",
    "    \"date_updated\":atts[\"updatedAt\"],\n",
    "    \"num_metadata\":len(metadata),\n",
    "    \"metadata\": metadata,\n",
    "    \"num_layers\":len(layers),\n",
    "    \"layers\": layers,\n",
    "    \"num_widgets\":len(widgets),\n",
    "    \"widgets\": widgets,\n",
    "    \"num_tags\":len(tags),\n",
    "    \"tags\":tags\n",
    "}\n",
    "\n",
    "# Create the DataFrame, name the index, and sort by date_updated\n",
    "# More recently updated datasets at the top\n",
    "new_ds_info = pd.DataFrame.from_dict(api_info, orient='index')\n",
    "new_ds_info.columns = [new_rw_id]\n",
    "new_ds_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_ds_info.loc['layers'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in data\n",
    "data = cc.read('com_009_flowmfa')\n",
    "\n",
    "# Read in flows\n",
    "flows = cc.read('com_009_flows')\n",
    "\n",
    "# Read in mfa13\n",
    "mfa13 = cc.read('com_009_mfa13')\n",
    "\n",
    "# Read in mfa4\n",
    "mfa4 = cc.read('com_009_mfa4')\n",
    "\n",
    "# Loop over years\n",
    "years = data['year'].unique()\n",
    "\n",
    "###\n",
    "# For each flow, make a layer for each of the 4 from mfa4, each of the 13 from mfa13\n",
    "layer_template = {'attributes': {'application': ['rw'],\n",
    "      'applicationConfig': {},\n",
    "      'dataset': new_rw_id,\n",
    "      'default': False,\n",
    "      'description': '',\n",
    "      'env': 'production',\n",
    "      'interactionConfig': reduce(lambda obj, col: setup_interaction_config(obj, col, data_tables[wri_id]), data_tables[wri_id].columns, []),\n",
    "      'iso': [],\n",
    "      'layerConfig': {'account': 'wri-rw',\n",
    "       'body': {'layers': [{'options': {'cartocss': cartocss,\n",
    "           'cartocss_version': '2.3.0',\n",
    "           'sql': gen_sql(data_col, table_name, date_col, year, filter_col, filter_val)},\n",
    "          'type': 'mapnik'}],\n",
    "        'maxzoom': 18,\n",
    "        'minzoom': 3}},\n",
    "      'legendConfig': {'items': legend,\n",
    "       'type': 'choropleth'},\n",
    "      'name': '',\n",
    "      'protected': False,\n",
    "      'provider': 'cartodb'},\n",
    "     'id': '',\n",
    "     'type': 'layer'}\n",
    "\n",
    "    if slider:\n",
    "        layer_template['attributes']['layerConfig']['timeline'] = True\n",
    "        layer_template['attributes']['layerConfig']['order'] = int(year)\n",
    "        layer_template['attributes']['layerConfig']['timelineLabel'] = str(year)\n",
    "\n",
    "{'attributes': {'application': ['rw'],\n",
    "  'applicationConfig': {},\n",
    "  'dataset': new_rw_id,\n",
    "  'default': True,\n",
    "  'description': 'The total weight of {flow} of {material} in {year} by country.',\n",
    "  'env': 'production',\n",
    "  'interactionConfig': {'output': []},\n",
    "  'iso': [],\n",
    "  'language': 'en',\n",
    "  'layerConfig': {'account': 'wri-rw',\n",
    "   'body': {'layers': [{'options': {'cartocss': '#com_009_flowmfa {polygon-opacity: 1; line-width: 0.5; line-color: #FFF; line-opacity: 1;} [value<100000]{polygon-fill:#f2f0f7 ;} [value>=100000][value<250000]{polygon-fill:#dadaeb ;} [value>=250000][value<500000]{polygon-fill:#bcbddc ;} [value>=500000][value<1000000]{polygon-fill:#9e9ac8 ;} [value>=1000000][value<3000000]{polygon-fill:#756bb1 ;} [value>=3000000][value<25000000]{polygon-fill:#54278f ;}',\n",
    "       'cartocss_version': '2.3.0',\n",
    "       'sql': 'SELECT geo.the_geom_webmercator, geo.cartodb_id, d.isoalpha3, d.flow, d.mfa13, d.time, d.sum_value FROM (SELECT isoalpha3, flow, mfa13, time, SUM(value) as sum_value FROM com_009_flowmfa WHERE flow ILIKE \"DMC\" AND mfa13 ILIKE \"GBF\" AND time = 2017 GROUP BY mfa13, isoalpha3, flow, time) d LEFT OUTER JOIN \"wri-rw\".wri_countries_a geo ON geo.iso_a3 = d.isoalpha3ORDER BY d.isoalpha3'},\n",
    "      'type': 'mapnik'}],\n",
    "    'maxzoom': 18,\n",
    "    'minzoom': 3}},\n",
    "  'legendConfig': {'items': [{'color': '#f2f0f7', 'name': '<100'},\n",
    "    {'color': '#dadaeb', 'name': '<250'},\n",
    "    {'color': '#bcbddc', 'name': '<500'},\n",
    "    {'color': '#9e9ac8', 'name': '<1000'},\n",
    "    {'color': '#756bb1', 'name': '<3000'},\n",
    "    {'color': '#54278f', 'name': '<25000'}],\n",
    "   'type': 'choropleth'},\n",
    "  'name': '2017 Domestic Extraction - Non-Metallic Minerals (tonnes, millions)',\n",
    "  'protected': False,\n",
    "  'provider': 'cartodb',\n",
    "  'slug': '2017-Domestic-Extraction-of-Raw-Materials',\n",
    "  'staticImageConfig': {},\n",
    "  'updatedAt': '2018-03-13T18:33:31.335Z',\n",
    "  'userId': '5981e73b0c069f3c93dc5e2a'},\n",
    " 'id': 'a7dbbf23-254a-49a3-a5dd-b12378fa345b',\n",
    " 'type': 'layer'}\n",
    "\n",
    "\n",
    "\n",
    "for layer in old_ds_info.loc['layers'].values[0]:\n",
    "    layer['attributes']['language'] = 'en'\n",
    "    layer['attributes']['application'] = ['rw']    \n",
    "    layer['attributes']['layerConfig']['body']['layers'][0]['options']['cartocss'] = layer['attributes']['layerConfig']['body']['layers'][0]['options']['cartocss'].replace(old_table_name, new_table_name)\n",
    "    layer['attributes']['layerConfig']['body']['layers'][0]['options']['sql'] = '' + \\\n",
    "    'SELECT geo.the_geom_webmercator, geo.cartodb_id, d.isoalpha3, d.flow, d.mfa4, d.time, d.sum_value FROM ' + \\\n",
    "    '(SELECT isoalpha3, flow, mfa4, time, SUM(value) as sum_value ' + \\\n",
    "    'FROM com_009_flowmfa WHERE flow ILIKE \"DMC\" AND mfa4 ILIKE \"BM\" AND time = 2017 ' + \\\n",
    "    'GROUP BY mfa4, isoalpha3, flow, time) d ' + \\\n",
    "    'LEFT OUTER JOIN \"wri-rw\".wri_countries_a geo ' + \\\n",
    "    'ON geo.iso_a3 = d.isoalpha3' + \\\n",
    "    'ORDER BY d.isoalpha3'\n",
    "    \n",
    "    _url = url.format(rw_id = new_rw_id, endpoint = 'layer')\n",
    "    res = req.request(\"POST\", _url, data=json.dumps(layer['attributes']), headers = headers)\n",
    "    logging.info(res.text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "old_ds_info.loc['layers'].values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
